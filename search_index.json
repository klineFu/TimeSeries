[["index.html", "A Minimal Book Example 前言", " A Minimal Book Example 思想先进的猫猫 2023-05-26 前言 这是时间序列的作业。我把这些作业汇总到了一个bookdown里面。但是由于一部分作业刚开始是手写的，就没有储存到里面。（哭） 值得注意的是，这是作业而不是课后习题（这是不同的） "],["第一章作业.html", "Chapter 1 第一章作业 1.1 复现课本图像 1.2 随机数的产生 1.3 课后习题", " Chapter 1 第一章作业 1.1 复现课本图像 利用R语言复现课本中的时间序列图像 1.1.1 强生公司季度收益序列 library(astsa) par(mfrow=2:1) tsplot(jj,ylab=&quot;QEPS&quot;,type=&quot;o&quot;,col=4,main=&quot;Johnson &amp; Johnson Quarterly Earnings&quot;) tsplot(log(jj),ylab=&quot;log(QEPS)&quot;,type=&quot;o&quot;,col=4) 1.1.2 全球变暖和气候变化 culer = c(rgb(.85,.30,.12,.6),rgb(.12,.65,.85,.6)) tsplot(gtemp_land,col=culer[1], lwd=2, type = &quot;o&quot;, pch = 20, ylab = &quot;Temperature Deviations&quot;, main = &quot;Global Warming&quot;) lines(gtemp_ocean,col=culer[2],lwd=2, type=&quot;o&quot;,pch=20) legend(&quot;topleft&quot;,col=culer,lty = 1,lwd=2, pch = 20, legend = c(&quot;Land Surface&quot;,&quot;Sea Surface&quot;),bg=&quot;white&quot;) 1.1.3 道琼斯工业平均指数 library(xts) djia_return= diff(log(djia$Close))[-1] par(mfrow=2:1) plot(djia$Close, col=4) plot(djia_return, col=4) 1.1.4 美国GDP对数增长率与实际增长率 tsplot(diff(log(gdp)),type = &quot;o&quot;, col = 4, ylab = &quot;GDP Growth&quot;) points(diff(gdp)/lag(gdp,-1),pch=3, col=2) 1.1.5 厄尔尼诺—南方涛动（ENSO） par(mfrow=2:1) tsplot(soi,ylab = &quot;&quot;, xlab = &quot;&quot;, main = &quot;Southern Dscillation Index&quot;,col = 4) text(1970, .91, &quot;COOL&quot;,col=&quot;cyan4&quot;) text(1970,- .91, &quot;WARN&quot;,col=&quot;darkmagenta&quot;) tsplot(rec, ylab = &quot;&quot;, main = &quot;Recruitment&quot;,col = 4) 1.1.6 捕食者与猎物的互动 culer = c(rgb(.85, .30, .12, .6),rgb(.12, .67, .86, .6)) tsplot(Hare, col = culer[1],lwd = 2,type = &quot;o&quot;, pch = 0, ylab = expression(Number~~~(&quot;&quot;%*% 1000))) lines(Lynx,col=culer[2],lwd=2,type=&quot;o&quot;, pch=2) legend(&quot;topright&quot;,col = culer,lty = 1, lwd=2, pch = c(0,2), legend = c(&quot;Hare&quot;,&quot;Lynx&quot;),bty = &quot;n&quot;) 1.1.7 fMRI图像 par(mfrow=c(3,1)) culer=c(rgb(.12,.67,.85,.7),rgb(.67,.12,.85,.7)) u=rep(c(rep(.6,16),rep(-.6,16)),4) tsplot(fmri1[,4],ylab=&quot;BOLD&quot;,xlab=&quot;&quot;,main=&quot;Cortex&quot;, col=culer[1],ylim=c(-.6,.6),lwd=2) lines(fmri1[,5],col=culer[2],lwd=2) lines(u,type=&quot;s&quot;) tsplot(fmri1[,6],ylab=&quot;BOLD&quot;,xlab=&quot;&quot;,main=&quot;Thalamus&quot;, col=culer[1],ylim=c(-.6,.6),lwd=2) lines(fmri1[,7],col=culer[2],lwd=2) lines(u,type=&quot;s&quot;) tsplot(fmri1[,8],ylab=&quot;BOLD&quot;,xlab=&quot;&quot;,main=&quot;Cerebellum&quot;, col=culer[1],ylim=c(-.6,.6),lwd=2) lines(fmri1[,9],col=culer[2],lwd=2) lines(u,type=&quot;s&quot;) mtext(&quot;Time (1 pt = 2 sec)&quot;,side=1,line=1.75) 1.1.8 滤波序列 par(mfrow=2:1) w=rnorm(500) v=filter(w,sides = 2,filter = rep(1/3,3)) # moving ave 1.1.9 自回归模型 set.seed(90210) w=rnorm(250+50) # 50 extra to avoid startup problems x=filter(w,filter = c(1.5,-.75),method = &quot;recursive&quot;)[-(1:50)] tsplot(x,main=&quot;autoregression&quot;,col=4) 1.1.10 带漂移项的随机游走序列 set.seed(314159265) # so you can reproduce the results w=rnorm(200);x =cumsum(w) # random walk wd = w +.3; xd = cumsum (wd) # random walk with drift tsplot(xd, ylim=c(-2,80),main=&quot;random walk&quot;, ylab=&quot;&quot;, co1=4) abline(a=0, b=.3, lty=2, co1=4) # plot drift lines (x, col=&quot;darkred&quot;) abline (h=0, col=&quot;darkred&quot;, lty=2) 1.1.11 信号与噪声 t=1:500 cs=2*cos(2*pi*(t+15)/50) #signal w= rnorm(500) #noise par(mfrow=c(3,1)) tsplot(cs, col=4,main=expression(2*cos(2*pi*(t+15)/50))) tsplot(cs+w, col=4,main=expression(2*cos(2*pi+(t+15)/50+N(0,1)))) tsplot(cs+5*w, col=4,main=expression(2*cos(2*pi*(t+15/50)+N(0,5^2)))) 1.2 随机数的产生 利用R语言，产生1000个服从标准正态分布的随机数，绘制散点图，计算样本均值与方差，并且标注在图形中。 # 导入ggplot2包 library(ggplot2) # 生成1000个服从标准正态分布的随机数 set.seed(123) # 设置随机数种子，以便复现结果 x &lt;- rnorm(1000) # 计算样本均值和方差 mean_x &lt;- mean(x) var_x &lt;- var(x) # 使用ggplot绘制散点图，并将样本均值和方差作为图例放置在图上 ggplot(data = data.frame(x = x, index = 1:1000), aes(x = index, y = x)) + geom_point(shape = 16) + labs(x = &quot;Index&quot;, y = &quot;Value&quot;, title = paste(&quot;Sample Mean:&quot;, round(mean_x, 2), &quot;,Sample Variance:&quot;, round(var_x, 2))) + theme(plot.title = element_text(hjust = 0.5, size = 12, face = &quot;bold&quot;), legend.title = element_blank(), legend.position = c(0.85, 0.85)) 1.3 课后习题 1.3.1 习题1.1 绘制\\(x_t\\)的线图，并把\\(v_t\\)作为线图作为虚线叠加 w = rnorm (150,0,1) # 50 extra to avoid startup problems xa=filter(w,filter=c(0,-.9),method=&quot;recursive&quot;)[-(1:50)] va = filter (xa, rep (1,4)/4, sides=1) # moving average tsplot(xa, main=&quot;autoregression&quot;) lines(va, col=2) 选取\\(x_t=2cos(\\frac{2\\pi t}{4})+w_t\\)，其中\\(w_t\\sim iidN(0,1)\\) w = rnorm (150,0,1) # 50 extra to avoid startup problems t=1:150 xa=(2*cos(2*pi*t/4)+w)[-(1:50)] va = filter (xa, rep (1,4)/4, sides=1) # moving average tsplot(xa, main=&quot;autoregression&quot;) lines(va, col=2) 选取\\(x_t\\)为取对数后的强生公司嫉妒收益率数据 library(astsa) xa=log(jj) va = filter (xa, rep (1,4)/4, sides=1) # moving average tsplot(xa, main=&quot;autoregression&quot;) lines(va, col=2) 季节调整（Seasonal adjustment）是指一种用于消除季节性波动影响的统计方法。季节性波动是指由于季节、节假日等因素引起的一种周期性变化，例如在冬季，因为天气寒冷，许多行业的销售会有所下降；而在夏季，因为气温升高，冰激凌、游泳池等与夏季相关的行业销售则会增加。为了对这些季节性因素进行更准确的分析，经济学家和统计学家通常会使用季节调整技术来消除季节性影响。这个过程包括计算出一个季节调整系数，该系数可以根据历史数据中的季节性模式来预测未来数据中的季节性影响，并将其从原始数据中剔除，以得到更准确的趋势分析结果。这样做可以让人们更好地理解经济或其他变量的发展趋势，同时避免因季节性因素而产生误导性的分析结果。 在进行统计分析的过程中，应当尽可能将可能影响数据的因素包含在考虑之中，如果分析过程中忽略了重要因素的影响就可能会导致错误的分析结果，上面的季节性因素就是一个典型的例子。 1.3.2 习题1.2 分别绘制地震序列和爆炸序列 par (mfrow=2:1) tsplot (EQ5, main=&quot;Earthquate&quot;) tsplot (EXP6, main=&quot;Explosion&quot;) 将两个线形绘制到同一个图表上 ts.plot(EQ5, EXP6, col=1:2) legend(&quot;topleft&quot;, lty=1, col=1:2, legend=c(&quot;EQ&quot; , &quot;EXP&quot;)) 地震序列通常具有相对较低的峰值频率。相比之下，爆炸序列其频率范围较窄，波形相对简单且更加规则。爆炸序列的幅度和频率通常比地震序列要小，而且通常具有相对较高的峰值频率。 1.3.3 习题1.3 生成9个随机游走序列 par(mfrow=c(3,3)) for (i in 1:9){ x = cumsum (rnorm (500)) tsplot (x) } 生成9个移动平均序列 w = rnorm (500) par(mfrow=c(3,3)) for (i in 1:9){ v=filter(w,sides = 2,filter = rep(1/3,3)) tsplot (v) } 移动平均得到的图像看起来十分的相似，而随机游走过程得到的图像彼此之间差别比较大。 1.3.4 习题1.4 绘制数据的时间序列图 tsplot(gdp, col = 4, ylab = &quot;GDP&quot;) 与1.3节中建立的模型相比，上述图像反映了时间与GDP之间的关系。 绘制图1.4 tsplot(diff(log(gdp)),type = &quot;o&quot;, col = 4, ylab = &quot;GDP Growth&quot;) points(diff(gdp)/lag(gdp,-1),pch=3, col=2) 两种方法分别采用了\\(r_t\\)和\\(log(1+r_t)\\)，观察绘制的图像，并且结合\\(log(1+r)\\)的Taylor展式 \\[\\begin{align} log(1+r_t)=r-\\frac{r^2}{2}+\\frac{r^3}{3}-···，-1&lt;r\\le 1 \\end{align}\\] 可以发现，采用\\(r_t\\)得到的结果更大，但是在r非常小的情况下可以忽略这种影响，近似认为两者等价。 1.3节中讨论到的带漂移项的随机游走序列最能描述美国GDP增长情况。 "],["第二章作业.html", "Chapter 2 第二章作业 Libs 2.1 2.11 高斯白噪声序列 2.2 2.12 移动平均序列 2.3 2.13 AR模型 2.4 2.14 信号加噪声模型", " Chapter 2 第二章作业 Libs 声明需要使用的包 library(astsa) 2.1 2.11 高斯白噪声序列 2.1.1 2.11 (a) 和例 1.7 一样，模拟长度为 n = 500 的一个高斯白噪声序列，然后计算其滞后 1 到 20 阶的样本 ACF，记作 \\(\\hat{\\rho}(h)\\)。把得到的结果与真实的 ACF 即 \\(\\rho(h)\\) 进行 比较。 w=rnorm(500) acf1(w,20) ## [1] -0.01 0.03 0.05 -0.04 0.02 0.00 -0.06 -0.02 -0.01 0.02 0.05 -0.02 ## [13] 0.01 0.07 0.02 0.03 -0.01 -0.04 0.03 0.04 2.1.2 2.11 (b) 设 n = 50，重复（a）。长度 n 是如何影响结果的？ w=rnorm(50) acf1(w,20) ## [1] -0.03 0.04 0.19 -0.01 -0.01 0.10 -0.05 -0.34 0.08 -0.09 -0.23 0.02 ## [13] -0.09 -0.12 -0.12 -0.01 -0.11 0.01 0.10 -0.07 长度 n 越长计算得到的ACF越小，得到的结果越准确。 2.2 2.12 移动平均序列 2.2.1 2.12 (a) 和例 1.8 一样，模拟长度为 n = 500 的一个移动平均序列，然后计算其滞后 1 到 20 阶样本 ACF 即 \\(\\hat{\\rho}(h)\\)。把得到的结果与真实的 ACF 即 \\(\\rho(h)\\) 进行 比较。 wa=rnorm(502,0,1) va=filter(wa,filter=rep(1/3.3)) acf1(va,20) ## [1] 0.02 0.09 -0.01 0.00 0.05 -0.03 0.03 0.01 0.03 0.05 -0.04 0.01 ## [13] -0.03 0.03 -0.01 0.01 0.01 0.05 -0.07 0.05 2.2.2 2.12 (b) 设 n = 50，重复（a）。长度 n 是如何影响结果的？ wa=rnorm(52,0,1) va=stats::filter(wa,rep(1/3,3)) acf1(va,20) ## [1] 0.50 0.25 -0.07 0.10 0.13 0.20 0.02 -0.06 -0.28 -0.15 -0.18 -0.07 ## [13] -0.18 -0.13 -0.14 0.01 -0.05 0.08 -0.04 0.07 长度 n 越长计算得到的ACF越小，得到的结果越准确。 2.3 2.13 AR模型 模拟一个例 1.9 中给出的 AR 模型，模拟序列长度为 n = 500。然后绘制其滞后 1 到 50 阶的样本 ACF。从样本 ACF 可以大致得到数据循环行为的什么结论？ set.seed(90210) w=rnorm(500+50) # 50 extra to avoid startup problems x=filter(w,filter = c(1.5,-.75),method = &quot;recursive&quot;)[-(1:50)] acf1(x,50) ## [1] 0.86 0.53 0.14 -0.21 -0.43 -0.49 -0.41 -0.24 -0.05 0.13 0.24 0.28 ## [13] 0.26 0.19 0.11 0.02 -0.04 -0.08 -0.10 -0.09 -0.08 -0.06 -0.04 -0.01 ## [25] 0.02 0.06 0.09 0.12 0.13 0.12 0.08 0.02 -0.05 -0.11 -0.14 -0.13 ## [37] -0.08 -0.01 0.07 0.12 0.14 0.11 0.06 -0.01 -0.06 -0.10 -0.11 -0.09 ## [49] -0.05 -0.03 随着样本ACF阶数的增加，ACF将逐渐收敛到0。 2.4 2.14 信号加噪声模型 4 模拟例 1.11 中给出的信号加噪声模型，其中（a）\\(\\sigma_{w}\\) = 0,（b）\\(\\sigma_{w}\\) = 1，（c）\\(\\sigma_{w}\\) = 5。模 拟序列长度为 n = 500。然后绘制生成的这三个序列的滞后 1 到 100 阶的样本 ACF。 从这三个序列的样本 ACF 可以大致得到数据循环行为的什么结论？ t=1:500 cs=2*cos(2*pi*(t+15)/50) #signal w1= rnorm(500,0,0) #noise w2= rnorm(500,0,1) w3= rnorm(500,0,5) par(mfrow=c(3,1)) acf1(cs, col=4,main=expression(2*cos(2*pi*(t+15)/50))) ## [1] 0.99 0.97 0.93 0.87 0.81 0.73 0.64 0.54 0.43 0.31 0.19 0.07 ## [13] -0.05 -0.17 -0.29 -0.40 -0.51 -0.61 -0.69 -0.77 -0.83 -0.88 -0.92 -0.94 ## [25] -0.95 -0.94 -0.92 -0.88 -0.83 -0.77 -0.69 -0.61 -0.51 acf1(cs+w, col=4,main=expression(2*cos(2*pi+(t+15)/50+N(0,1)))) ## [1] 0.65 0.62 0.63 0.57 0.51 0.48 0.42 0.36 0.27 0.22 0.15 0.05 ## [13] -0.05 -0.07 -0.20 -0.27 -0.32 -0.40 -0.48 -0.49 -0.59 -0.59 -0.61 -0.65 ## [25] -0.62 -0.62 -0.63 -0.57 -0.56 -0.50 -0.45 -0.41 -0.36 -0.26 acf1(cs+5*w, col=4,main=expression(2*cos(2*pi*(t+15/50)+N(0,5^2)))) ## [1] 0.07 0.04 0.12 0.07 0.01 0.05 0.05 0.07 -0.01 0.06 0.07 0.03 ## [13] -0.04 0.10 -0.04 -0.04 0.01 -0.03 -0.11 0.01 -0.15 -0.06 -0.06 -0.12 ## [25] -0.04 -0.05 -0.11 -0.03 -0.08 -0.02 -0.02 -0.06 -0.10 0.00 方差越大样本的ACF越小。 "],["第三章作业.html", "Chapter 3 第三章作业 Libs 3.1 3.1 结构回归模型 3.2 3.2 检验的死亡率数据 3.3 3.3 随机游走和趋势平稳过程之间的区别 3.4 3.4 线性趋势组成的过程 3.5 3.5 平稳性证明 3.6 3.6 冰川纹层数据 3.7 3.7 全球温度序列 3.8 3.8 厄尔尼诺现象 3.9 3.9 强生公司数据序列", " Chapter 3 第三章作业 Libs pacman::p_load(astsa,tidyverse,ggplot2,reshape2) 3.1 3.1 结构回归模型 3.1.1 3.1 (a) 拟合回归模型： trend = time(jj) - 1970 Q = factor(cycle(jj)) reg = lm(log(jj)~0+trend+Q,na.action = NULL) head(model.matrix(reg)) ## trend Q1 Q2 Q3 Q4 ## 1 -10.00 1 0 0 0 ## 2 -9.75 0 1 0 0 ## 3 -9.50 0 0 1 0 ## 4 -9.25 0 0 0 1 ## 5 -9.00 1 0 0 0 ## 6 -8.75 0 1 0 0 summary(reg) ## ## Call: ## lm(formula = log(jj) ~ 0 + trend + Q, na.action = NULL) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.29318 -0.09062 -0.01180 0.08460 0.27644 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## trend 0.167172 0.002259 74.00 &lt;2e-16 *** ## Q1 1.052793 0.027359 38.48 &lt;2e-16 *** ## Q2 1.080916 0.027365 39.50 &lt;2e-16 *** ## Q3 1.151024 0.027383 42.03 &lt;2e-16 *** ## Q4 0.882266 0.027412 32.19 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1254 on 79 degrees of freedom ## Multiple R-squared: 0.9935, Adjusted R-squared: 0.9931 ## F-statistic: 2407 on 5 and 79 DF, p-value: &lt; 2.2e-16 3.1.2 3.1 (b) 如果模型正确，根据summary()得到的结果平均每股对数收益率的年增长的估计值是0.167172。 3.1.3 3.1 (c) 如果模型正确，平均对数收益率从第三季度到第四季度会减少，根据summary()得到的结果，减少的百分比是Q4-Q3=0.268758 3.1.4 3.1 (d) 如果在(a)中的模型中包含截距项，第四季度分量将变成负的。 reg2 = lm(log(jj)~0+trend+Q+1,na.action = NULL) head(model.matrix(reg2)) ## (Intercept) trend Q2 Q3 Q4 ## 1 1 -10.00 0 0 0 ## 2 1 -9.75 1 0 0 ## 3 1 -9.50 0 1 0 ## 4 1 -9.25 0 0 1 ## 5 1 -9.00 0 0 0 ## 6 1 -8.75 1 0 0 summary(reg2) ## ## Call: ## lm(formula = log(jj) ~ 0 + trend + Q + 1, na.action = NULL) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.29318 -0.09062 -0.01180 0.08460 0.27644 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.052793 0.027359 38.480 &lt; 2e-16 *** ## trend 0.167172 0.002259 73.999 &lt; 2e-16 *** ## Q2 0.028123 0.038696 0.727 0.4695 ## Q3 0.098231 0.038708 2.538 0.0131 * ## Q4 -0.170527 0.038729 -4.403 3.31e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1254 on 79 degrees of freedom ## Multiple R-squared: 0.9859, Adjusted R-squared: 0.9852 ## F-statistic: 1379 on 4 and 79 DF, p-value: &lt; 2.2e-16 3.1.5 3.1 (e) 绘制数据\\(x_t\\)并在图表上叠加拟合值 a &lt;- data.frame(Time=c(time(log(jj))),logjj=c(log(jj)),fit=reg$fitted.values) a &lt;- melt(a,id=&quot;Time&quot;) ## Warning: attributes are not identical across measure variables; they will be ## dropped p_line=ggplot(group_by(a),aes(x=Time,y=value,group=variable,col=variable))+ geom_line()+ xlab(&quot;Time&quot;)+ ylab(&quot;log(QEPS)&quot;) p_line 检查残差，首先观察Q-Q图 tsplot(reg$residuals) tibble(reg$residuals) %&gt;% ggplot(aes(sample = reg$residuals)) + geom_qq() + geom_qq_line() ## Don&#39;t know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting ## to continuous. ## Don&#39;t know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting ## to continuous. 使用Box-Ljung 检验来检测残差是否是白噪声 #Box-Ljung 检验 Box.test(reg$residuals,type=&#39;Ljung&#39;,lag=log(length(reg$residuals))) ## ## Box-Ljung test ## ## data: reg$residuals ## X-squared = 54.362, df = 4.4308, p-value = 8.166e-11 由于pvalue小于0.5，因此残差不是白噪声。 3.2 3.2 检验的死亡率数据 3.2.1 3.2 (a) 在式 (3.17) 中为回归添加另一个分量，该分量考虑了四周前的颗粒物数量。将\\(P_{t-4}\\) 添加到式 (3.17) 的回归中 temp = tempr-mean(tempr) ded = ts.intersect(cmort,trend=time(cmort),temp,temp2=temp^2, part,partL4=stats::lag(part,-4)) n&lt;-length(ded)/6 fit = lm(ded[1:n,1]~ ded[1:n,2] + ded[1:n,3] + ded[1:n,4] + ded[1:n,5] + ded[1:n,6], na.action=NULL) summary(fit) ## ## Call: ## lm(formula = ded[1:n, 1] ~ ded[1:n, 2] + ded[1:n, 3] + ded[1:n, ## 4] + ded[1:n, 5] + ded[1:n, 6], na.action = NULL) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18.228 -4.314 -0.614 3.713 27.800 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.808e+03 1.989e+02 14.123 &lt; 2e-16 *** ## ded[1:n, 2] -1.385e+00 1.006e-01 -13.765 &lt; 2e-16 *** ## ded[1:n, 3] -4.058e-01 3.528e-02 -11.503 &lt; 2e-16 *** ## ded[1:n, 4] 2.155e-02 2.803e-03 7.688 8.02e-14 *** ## ded[1:n, 5] 2.029e-01 2.266e-02 8.954 &lt; 2e-16 *** ## ded[1:n, 6] 1.030e-01 2.485e-02 4.147 3.96e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.287 on 498 degrees of freedom ## Multiple R-squared: 0.608, Adjusted R-squared: 0.6041 ## F-statistic: 154.5 on 5 and 498 DF, p-value: &lt; 2.2e-16 得到的回归结果如上。 3.2.2 3.2 (b) 计算AIC和BIC num=length(cmort) AIC(fit)/num-log(2*pi) ## [1] 4.641492 BIC(fit)/num-log(2*pi) ## [1] 4.699677 与例 3.5 中最终模型对比可以发现AIC,BIC的值更小了。因此，(a)中模型是对3.5 中最终模型的改进。 3.3 3.3 随机游走和趋势平稳过程之间的区别 3.3.1 3.3 (a) 生成四个带漂移项的随机游走序列 par(mrow=c(2,2)) ## Warning in par(mrow = c(2, 2)): &quot;mrow&quot; is not a graphical parameter for (i in 1:4) { x = ts(cumsum(rnorm(500,.01,1))) regx=lm(x~0+time(x),na.action = NULL) tsplot(x,ylab = &quot;Random Walk w Drift&quot;,col=&quot;darkgray&quot;) abline(a=0,.01,col=2,lty=2) abline(regx,col(4)) } 3.3.2 3.3 (b) 生成四个序列，长度 n = 500，它们是线性趋势加上噪声 par(mrow=c(2,2)) ## Warning in par(mrow = c(2, 2)): &quot;mrow&quot; is not a graphical parameter t=1:500 for (i in 1:4) { y = ts(rnorm(500,.01,1)+0.01*t) regx=lm(y~0+time(y),na.action = NULL) tsplot(y,ylab = &quot;Random Walk w Drift&quot;,col=&quot;darkgray&quot;) abline(a=0,.01,col=2,lty=2) abline(regx,col(4)) } 3.3.3 3.3 (c) (a)中得到的四个结果之间存在较大的差异，而(b)中得到的结果尽管存在差异，但是差异很小，并且(b)中得到的图像总是具有相同的趋势。这是因为\\(0.01t\\)在起作用。 3.4 3.4 线性趋势组成的过程 3.4.1 3.4 (a) 证明 \\(x_t\\) 是非平稳的。 \\[\\begin{align} \\mu_{x_t}&amp;=E[x_{t}]\\notag\\\\ &amp;=\\beta_{0}+\\beta_{1}t\\notag \\end{align}\\] 由于均值函数和时间有关，因此不是平稳的。 3.4.2 3.4 (b) 通过找出其均值和自协方差函数证明一阶差分序列是平稳的。 \\[\\begin{align} \\nabla x_{t}&amp;= x_{t}-x_{t-1}\\notag\\\\ &amp;=\\beta_{0}+\\beta_{1}t-\\beta_{0}-\\beta_{1}(t-1)-w_{t-1}\\notag\\\\ &amp;=\\beta_{1}+w_{t}-w_{t-1}\\notag \\end{align}\\] 其均值和自协方差函数分别如下： \\[\\begin{align} \\mu_{\\nabla x_{t}}&amp;=E[\\nabla x_{t}]=\\beta_{1}\\notag\\\\ \\gamma(h)&amp;=cov(\\beta_{1}+w_{t}-w_{t-1},\\beta_{1}+w_{t+h}-w_{t+h-1})\\notag\\\\ &amp;=\\left\\{ \\begin{array}{rcl} &amp;2\\sigma_{w}^{2} &amp; {h=0}\\\\ &amp;-\\sigma_{w}^{2} &amp; {|h|=1}\\\\ &amp;0 &amp; {2\\leq |h|}\\notag \\end{array} \\right. \\end{align}\\] 由于均值函数与t无关，并且自协方差函数仅与h有关，所以该序列平稳。 3.4.3 3.4 (c) 果用一般的平稳过程（即 \\(y_t\\)）代替 \\(w_t\\)， \\[\\begin{align} \\nabla x_{t}&amp;= \\beta_{1}+y_{t}-y_{t-1}\\notag \\end{align}\\] 其均值和自协方差函数分别如下： \\[\\begin{align} \\mu_{\\nabla x_{t}}&amp;=E[\\nabla x_{t}]=\\beta_{1}\\notag\\\\ \\gamma(h)&amp;=cov(\\beta_{1}+y_{t}-y_{t-1},\\beta_{1}+y_{t+h}-y_{t+h-1})\\notag\\\\ &amp;=\\left\\{ \\begin{array}{rcl} &amp;2\\sigma_{y}^{2} &amp; {h=0}\\\\ &amp;-\\sigma_{y}^{2} &amp; {|h|=1}\\\\ &amp;0 &amp; {2\\leq |h|}\\notag \\end{array} \\right. \\end{align}\\] 由于均值函数与t无关，并且自协方差函数仅与h有关，所以该序列平稳。 3.5 3.5 平稳性证明 序列为： \\[\\begin{align} \\nabla x_{t}&amp;= x_{t}-x_{t-1}\\notag\\\\ &amp;= \\sigma+w_{t}+y_{t}-y_{t-1}\\notag \\end{align}\\] 其均值和自协方差函数分别如下： \\[\\begin{align} \\mu_{\\nabla x_{t}}&amp;=E[\\nabla x_{t}]=\\sigma\\notag\\\\ \\gamma(h)&amp;=cov(\\sigma+w_{t}+y_{t}-y_{t-1},\\sigma+w_{t+h}+y_{t+h}-y_{t+h-1})\\notag\\\\ &amp;=\\left\\{ \\begin{array}{rcl} &amp;2\\sigma_{y}^{2}+\\sigma_{w}^{2} &amp; {h=0}\\\\ &amp;\\sigma_{y}^{2} &amp; {|h|=1}\\\\ &amp;\\sigma_{y}^{2} &amp; {|h|=2}\\\\ &amp; 0 &amp; {3\\leq |h|}\\notag \\end{array} \\right. \\end{align}\\] 3.6 3.6 冰川纹层数据 3.6.1 3.6 (a) 在数据的前半部分和后半部分计算样本方差： x=varve y=log(varve) n=length(x)/2 N=length(x) var(x[1:n]) ## [1] 133.4574 var(x[n:N]) ## [1] 592.9645 这表明数据存在异方差性。 进行变换\\(y_t=log(x_t)\\)后，再次在数据的前半部分和后半部分计算样本方差： n=length(y)/2 N=length(y) var(y[1:n]) ## [1] 0.2707217 var(y[n:N]) ## [1] 0.4506843 这说明变换稳定了序列的方差。 绘制直方图： hist(x) hist(y) 观察直方图可以发现数据向中间靠拢，这表明通过变换数据改善了对正态性的近似。 3.6.2 3.6 (b) 绘制序列\\(y_t\\) tsplot(y) 存在100年的时间间隔，可以观察到与图1.2中的全球温度记录中观察到的行为相当的行为。 3.6.3 3.6 (c) 检查\\(y_t\\)的样本ACF，并绘制图像 acf1(y) ## [1] 0.59 0.51 0.46 0.46 0.46 0.46 0.43 0.43 0.41 0.37 0.37 0.33 0.34 0.38 0.36 ## [16] 0.35 0.34 0.33 0.30 0.31 0.36 0.36 0.32 0.33 0.31 0.29 0.30 0.27 0.28 0.28 ## [31] 0.28 0.28 0.23 0.23 0.25 0.23 可以发现样本ACF较高，这说明进行变换后时间序列\\(y_t\\)仍然存在问题 3.6.4 3.6 (d) 计算差分\\(u_t=y_t-y_{t-1}\\)，检查其时序图以及样本ACF u=y-stats::lag(y,1) tsplot(u) acf1(u) ## [1] -0.40 -0.04 -0.06 0.01 0.00 0.04 -0.04 0.04 0.01 -0.05 0.06 -0.06 ## [13] -0.04 0.08 -0.02 0.01 0.00 0.03 -0.05 -0.06 0.07 0.04 -0.06 0.05 ## [25] -0.01 -0.04 0.05 -0.05 0.03 -0.02 0.00 0.06 -0.05 -0.03 0.04 -0.05 这表明差分对数纹层数据得到了一个相当稳定的序列。\\(u_t\\)实际上是除去了时间影响的一个序列，这使得它近似一个白噪声。 3.7 3.7 全球温度序列 3.7.1 3.7 移动平均平滑器 w = c(.5, rep(1,11), .5)/12 gtemp_landf = stats::filter(gtemp_land, sides=2, filter=w) culer = c(rgb(.85,.30,.12,.6),rgb(.12,.65,.85,.6)) tsplot(gtemp_landf,col=culer[1], lwd=2, type = &quot;o&quot;, pch = 20, ylab = &quot;Temperature Deviations&quot;, main = &quot;Global Warming&quot;) lines(gtemp_ocean,col=culer[2],lwd=2, type=&quot;o&quot;,pch=20) legend(&quot;topleft&quot;,col=culer,lty = 1,lwd=2, pch = 20, legend = c(&quot;Land Surface&quot;,&quot;Sea Surface&quot;),bg=&quot;white&quot;) 3.7.2 3.7 核平滑 culer = c(rgb(.85,.30,.12,.6),rgb(.12,.65,.85,.6)) tsplot(gtemp_land,col=culer[1], lwd=2, type = &quot;o&quot;, pch = 20, ylab = &quot;Temperature Deviations&quot;, main = &quot;Global Warming&quot;) lines(ksmooth(time(gtemp_ocean), gtemp_ocean, &quot;normal&quot;, bandwidth=1), lwd=2, col=6) legend(&quot;topleft&quot;,col=culer,lty = 1,lwd=2, pch = 20, legend = c(&quot;Land Surface&quot;,&quot;Sea Surface&quot;),bg=&quot;white&quot;) 3.7.3 3.7 lowess culer = c(rgb(.85,.30,.12,.6),rgb(.12,.65,.85,.6)) tsplot(gtemp_land,col=culer[1], lwd=2, type = &quot;o&quot;, pch = 20, ylab = &quot;Temperature Deviations&quot;, main = &quot;Global Warming&quot;) lines(lowess(gtemp_ocean, f=.05), lwd=2, col=4) legend(&quot;topleft&quot;,col=culer,lty = 1,lwd=2, pch = 20, legend = c(&quot;Land Surface&quot;,&quot;Sea Surface&quot;),bg=&quot;white&quot;) 3.8 3.8 厄尔尼诺现象 trnd = time(soi) C4 = cos(2*pi*trnd/4) S4 = sin(2*pi*trnd/4) tsplot(C4, col=astsa.col(4,.6)) lines(lowess(C4, f=.05), lwd=2, col=4) tsplot(S4, col=astsa.col(4,.6)) lines(lowess(S4, f=.05), lwd=2, col=4) 3.9 3.9 强生公司数据序列 使用例 3.20 中提到的方法将滞后数据分解为 \\(x_t=T_t+S_t+N_t\\)，可得结果如下： culer = c(5, 4, 2, 6) x = log(jj) par(mfrow = c(4,1), cex.main=1) out = stl(x, s.window=15)$time.series tsplot(x, main=&#39;Johnson &amp; Johnson Quarterly Earnings&#39;, ylab=&#39;log(QEPS)&#39;, col=8) text(x, labels=1:4, col=culer, cex=1.25) tsplot(out[,1], main=&quot;Seasonal&quot;, ylab=&#39;log(QEPS)&#39;,col=8) text(out[,1], labels=1:4, col=culer, cex=1.25) tsplot(out[,2], main=&quot;Trend&quot;, ylab=&#39;log(QEPS)&#39;, col=8) text(out[,2], labels=1:4, col=culer, cex=1.25) tsplot(out[,3], main=&quot;Noise&quot;, ylab=&#39;log(QEPS)&#39;, col=8) text(out[,3], labels=1:4, col=culer, cex=1.25) 3.1中分解得到的“白噪声”数据并不是真正的白噪声，相比之下，3.9采用的方法可以更好的分解数据。 "],["第四章作业.html", "Chapter 4 第四章作业 Libs 4.1 4.1 MA(1)的ACF 4.2 4.2 白噪声过程 4.3 4.3 参数冗余的讨论 4.4 4.4 三个ARMA模型 4.5 4.5 cmort数据分析 4.6 4.6 模型预测与MSPE 4.7 4.7 参数估计 4.8 4.8 参数的MLE 4.9 4.9 AR(1)的高斯-牛顿算法 4.10 4.10 预测误差", " Chapter 4 第四章作业 Libs pacman::p_load(astsa,tidyverse,ggplot2,reshape2,forecast) 4.1 4.1 MA(1)的ACF MA(1)模型为： \\[ x_{t}=w_t +\\theta w_{t-1} \\] 根据自相关函数的定义，可知MA(1)的自相关函数为： \\[\\begin{align} \\rho_{x}(1)=\\frac{\\gamma(1)}{\\gamma(0)}&amp;=\\frac{cov(x_t,x_{t+1})}{cov(x_t,x_t)}\\notag\\\\ &amp;=\\frac{\\theta}{1+\\theta^2}\\notag \\end{align}\\] 对MA(1)的ACF进行求导，可得： \\[\\begin{align} \\rho_{x}^{&#39;}(1)=\\frac{1+\\theta-2\\theta^2}{(1+\\theta^2)^2}\\notag \\end{align}\\] 令ACF等于0，可以解得： \\[ \\theta_{1}=-\\frac{1}{2}, \\theta_{2}=1 \\] 故可知，当\\(\\theta=1\\)时，ACF有最大值： \\[ max \\rho_{x}^{}(1)=\\frac{1}{2} \\] 当\\(\\theta=-\\frac{1}{2}\\)时，ACF有最小值： \\[ min \\rho_{x}^{}(1)=-\\frac{2}{5} \\] 因此，也证明了下式： \\[ |\\rho_{x}(1)|\\le1/2 \\] 实际上，也可以利用R来简单的观察到函数的大致性质： curve(x/(1+x^2),from = -10, to=10) \\(\\square\\) 4.2 4.2 白噪声过程 4.2.1 (a) 使用数学归纳法来证明命题，在\\(t=1\\)时： \\[\\begin{align} x_{1}&amp;=\\phi x_{0}+w_{1}\\notag\\\\ &amp;=\\phi w_{0}+w_{1}\\notag\\\\ &amp;=\\sum_{j=0}^{t}\\phi^{j}w_{1-j}\\notag \\end{align}\\] 命题成立。现假设\\(t-1\\)时命题为真，即为： \\[ x_{t-1} =\\sum_{j=0}^{t-1}\\phi^{j}w_{t-1-j} \\] 那么在等于\\(t\\)时： \\[\\begin{align} x_{t}&amp;=\\phi x_{t-1}+w_{t}\\notag\\\\ &amp;=\\phi \\sum_{j=0}^{t-1}\\phi^{j}w_{t-1-j}+w_{t}\\notag\\\\ &amp;=\\sum_{j=0}^{t}\\phi^{j}w_{t-j}\\notag \\end{align}\\] 由归纳法得知，命题得证。 \\(\\square\\) 4.2.2 (b) 求期望\\(E[x_{t}]\\): \\[\\begin{align} E[x_{t}] &amp;=E[\\sum_{j=0}^{t}\\phi^{j}w_{t-j}]\\notag\\\\ &amp;=\\sum_{j=0}^{t}\\phi^{j} E[w_{t-j}]\\notag\\\\ &amp;=0 \\notag \\end{align}\\] \\(\\square\\) 4.2.3 (c) 根据方差的性质： \\[ Var(ax)=a^{2}Var(x) \\] 以及公式： \\[ \\sum_{j=0}^{k}a_{j}=(1-a^{k+1})/(1-a) \\] 故可知\\(Var(x_{t})\\)为： \\[\\begin{align} Var[x_{t}] &amp;=Var[\\sum_{j=0}^{t}\\phi^{j}w_{t-j}]\\notag\\\\ &amp;=\\sum_{j=0}^{t}\\phi^{2j} Var[w_{t-j}]\\notag\\\\ &amp;=\\sigma_{w}^{2}\\sum_{j=0}^{t}\\phi^{2j} \\notag\\\\ &amp;=\\frac{\\sigma_{w}^{2}}{1-\\phi_{2}}(1-\\phi^{2(t+1)})\\notag \\end{align}\\] \\(\\square\\) 4.2.4 (d) 利用前几问的结果，可以将 \\(x_{t+h}\\)表示为： \\[ x_{t+h}=\\phi^{h}x_{t}+\\sum_{j=0}^{h-1}\\phi^{j}w_{t+h-j} \\] 利用上式，可以计算\\(cov(x_{t+h},x_{t})\\): \\[\\begin{align} cov(x_{t+h,x},x_{t})&amp;=cov(\\phi^{h}x_{t}+\\sum_{j=0}^{h-1}\\phi^{j}w_{t+h-j},x_{t})\\notag\\\\ &amp;=\\phi^{h}cov(x_{t},x_{t})+cov(\\sum_{j=0}^{h-1}\\phi^{j}w_{t+h-j},x_{t})\\notag\\\\ &amp;=\\phi^{h}Var(x_{t})\\notag \\end{align}\\] \\(\\square\\) 4.2.5 (e) 由于序列的方差与时间有关，因此序列不是平稳的。 4.2.6 (f) 当\\(t\\to \\infty\\)时，可以发现： \\[ Var(x_{t})=\\frac{\\sigma_{w}^{2}}{1-\\phi_{2}}(1-\\phi^{2(t+1)})\\to\\frac{\\sigma_{w}^{2}}{1-\\phi_{2}} (|\\phi|&lt;1) \\] 即\\(t\\to \\infty\\)时，方差与\\(t\\)的关系逐渐消失，因此\\(x_{t}\\)是渐进平稳的。 4.2.7 (g) 生成n个以上的观测值，并丢弃最初生成的观测值。 4.2.8 (h) 根据题意，可以将\\(x_{t}\\)表示为: \\[ x_{t}=\\phi^{t}x_{0}+\\sum_{j=0}^{t-1}\\phi^{j} w_{t-j} \\] 则可知\\(Var(x_{t})\\)为： \\[\\begin{align} Var[x_{t}] &amp;= Var[\\sum_{j=0}^{t-1}\\phi^{j}w_{t-j}] + Var[\\phi^{t}x_{0}]\\notag\\\\ &amp;=\\sum_{j=0}^{t-1}\\phi^{2j} Var[w_{t-j}] + Var[\\phi^{t}\\frac{w_{0}}{\\sqrt{1-\\phi^2}}]\\notag\\\\ &amp;=\\sigma_{w}^{2}\\sum_{j=0}^{t-1}\\phi^{2j}-\\frac{\\phi^{2t}}{1-\\phi^{2}}Var[w_{0}] \\notag\\\\ &amp;=\\frac{\\sigma_{w}^{2}}{1-\\phi_{2}}(1-\\phi^{2t})-\\frac{\\sigma_{w}^{2}}{1-\\phi_{2}}\\phi^{2t}\\notag\\\\ &amp;=\\frac{\\sigma_{w}^{2}}{1-\\phi_{2}}\\notag \\end{align}\\] 即方差与时间\\(t\\)无关。同时易知\\(x_{t}\\)的期望仍然为0。因此可以得知，这个过程是平稳的。 \\(\\square\\) 4.3 4.3 参数冗余的讨论 4.3.1 (a) 模型1可以表示为： \\[ (1-0.3B)(1-0.5B)x_{t}=(1-0.3B)w_{t} \\] 等式两边可以约分，因此模型1存在参数冗余。化简后的模型为： \\[ x_{t}=0.5x_{t-1}+w_{t} \\] 这是一个AR模型。 模型2可以表示为： \\[ (1-B+0.5B^{2})x_{t}=(1-B)w_{t} \\] 等式两边无法约分，因此模型2不存在参数冗余。 4.3.2 (b) 模型(i) AR(1)模型 \\(\\phi\\)的根大于1，因此模型(i)为因果模型。 模型(ii) ARMA(2,1)模型 \\(\\phi\\)的根大于1，因此模型(ii)为因果模型。\\(\\theta\\)的根等于1，因此模型(ii)不是可逆模型。 Mod(polyroot(c(1,-.5))) ## [1] 2 Mod(polyroot(c(1,-.1,.5))) ## [1] 1.414214 1.414214 Mod(polyroot(c(1,-1))) ## [1] 1 4.3.3 (c) 模型(i)的因果系数和可逆系数 round(ARMAtoMA(ar = .5, ma = 0 , 50),3)#前50个因果系数 ## [1] 0.500 0.250 0.125 0.062 0.031 0.016 0.008 0.004 0.002 0.001 0.000 0.000 ## [13] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [25] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [37] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [49] 0.000 0.000 round(ARMAtoAR(ar = .5, ma = 0 , 50),3)#前五十个可逆系数 ## [1] -0.5 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ## [16] 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ## [31] 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ## [46] 0.0 0.0 0.0 0.0 0.0 模型(ii)的因果系数和可逆系数 round(ARMAtoMA(ar = c(1.-.5), ma = -1 , 50),3)#前50个因果系数 ## [1] -0.500 -0.250 -0.125 -0.062 -0.031 -0.016 -0.008 -0.004 -0.002 -0.001 ## [11] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [21] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [31] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## [41] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 round(ARMAtoAR(ar = c(1,-.5), ma = -1 , 50),3)#前五十个可逆系数 ## [1] 0.0 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ## [20] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ## [39] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 4.4 4.4 三个ARMA模型 4.4.1 (a) 首先，针对三个不同的ARMA模型，绘制它们的ACF和PACF： #ARMA(1,1) ACF = ARMAacf(ar=.6, ma=.9, 24)[-1] PACF = ARMAacf(ar=.6, ma=.9, 24, pacf=TRUE) par(mfrow=1:2) tsplot(ACF, type=&quot;h&quot;, xlab=&quot;lag&quot;, ylim=c(-.8,1)) abline(h=0, col=8) title(&quot;ARMA(1,1)&quot;) tsplot(PACF, type=&quot;h&quot;, xlab=&quot;lag&quot;, ylim=c(-.8,1)) abline(h=0, col=8) title(&quot;ARMA(1,1)&quot;) #ARMA(1,0) ACF = ARMAacf(ar=0.6, ma=0, 24)[-1] PACF = ARMAacf(ar=0.6, ma=0, 24, pacf=TRUE) par(mfrow=1:2) tsplot(ACF, type=&quot;h&quot;, xlab=&quot;lag&quot;, ylim=c(-.8,1)) abline(h=0, col=8) title(&quot;ARMA(1,0)&quot;) tsplot(PACF, type=&quot;h&quot;, xlab=&quot;lag&quot;, ylim=c(-.8,1)) abline(h=0, col=8) title(&quot;ARMA(1,0)&quot;) #ARMA(0,1) ACF = ARMAacf(ar=0, ma=0.9, 24)[-1] PACF = ARMAacf(ar=0, ma=0.9, 24, pacf=TRUE) par(mfrow=1:2) tsplot(ACF, type=&quot;h&quot;, xlab=&quot;lag&quot;, ylim=c(-.8,1)) abline(h=0, col=8) title(&quot;ARMA(0,1)&quot;) tsplot(PACF, type=&quot;h&quot;, xlab=&quot;lag&quot;, ylim=c(-.8,1)) abline(h=0, col=8) title(&quot;ARMA(0,1)&quot;) 各类模型的ACF，PACF表现如下表所示： AR(p) MA(q) ARMA(p,q) ACF 拖尾 在滞后q处截尾 拖尾 PACF 在滞后p处截尾 拖尾 拖尾 ACF可以确定MA(q)模型的阶数q，PACF可以确定AR(p)模型的阶数p。对于ARMA(p,q)模型，无法使用ACF，PACF来判断它的具体阶数。 4.4.2 (b) 取样本数为\\(n=100\\)，分别绘制三个模型的ACF，PACF： ARMA(1,1) arma&lt;-arima.sim(list(order=c(1,0,1),ar=.6,ma=.9),n=100) acf2(arma) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## ACF 0.7 0.24 0.05 0.04 0 -0.11 -0.19 -0.21 -0.21 -0.23 -0.22 -0.15 -0.07 ## PACF 0.7 -0.49 0.36 -0.19 0 -0.16 0.00 -0.11 -0.07 -0.12 0.02 -0.03 -0.02 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] ## ACF -0.06 -0.11 -0.08 -0.02 -0.02 0.03 0.18 ## PACF -0.13 -0.05 0.06 -0.18 0.01 0.15 0.14 ARMA(1,0) arma&lt;-arima.sim(list(order=c(1,0,0),ar=.6),n=100) acf2(arma) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## ACF 0.6 0.27 0.05 -0.15 -0.22 -0.12 0.01 0.09 0.07 0.11 0.09 0.05 ## PACF 0.6 -0.13 -0.08 -0.19 -0.02 0.11 0.09 -0.01 -0.08 0.10 0.02 0.03 ## [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] ## ACF -0.04 -0.07 -0.02 0.03 0.11 0.05 0.08 0.08 ## PACF -0.12 0.00 0.10 0.07 0.07 -0.20 0.15 0.04 ARMA(0,1) arma&lt;-arima.sim(list(order=c(0,0,1),ma=.9),n=100) acf2(arma) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## ACF 0.54 0.04 -0.03 -0.09 -0.19 -0.26 -0.16 -0.01 -0.01 -0.01 0.07 0.17 ## PACF 0.54 -0.36 0.22 -0.28 0.00 -0.22 0.15 -0.10 0.00 -0.03 0.07 0.10 ## [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] ## ACF 0.18 0.07 0.00 -0.03 -0.12 -0.26 -0.31 -0.18 ## PACF 0.02 -0.02 0.01 -0.06 -0.06 -0.20 -0.06 -0.02 观察发现，样本容量\\(n=100\\)时，ACF，PACF可能不太准确，与理论值存在比较大的误差。ARMA(1,0)模型的PACF本应该在LAG=1处截尾，ARMA(0,1)模型的ACF也应该在LAG=1处截尾。但是，实际上得到的结果并不支持这一结论。 4.4.3 (c) 重新选取样本容量\\(n=500\\)，分别绘制三个模型的ACF，PACF： ARMA(1,1) arma&lt;-arima.sim(list(order=c(1,0,1),ar=.6,ma=.9),n=500) acf2(arma) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## ACF 0.81 0.49 0.26 0.11 0.04 0.01 -0.01 -0.01 0.00 -0.01 -0.05 -0.10 -0.14 ## PACF 0.81 -0.48 0.24 -0.21 0.20 -0.16 0.08 -0.02 0.02 -0.08 -0.03 -0.07 -0.02 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] ## ACF -0.16 -0.17 -0.16 -0.16 -0.15 -0.15 -0.15 -0.14 -0.13 -0.11 -0.1 -0.08 ## PACF -0.04 -0.02 -0.05 -0.01 -0.07 0.00 -0.07 0.02 -0.05 -0.01 0.0 -0.04 ## [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] ## ACF -0.07 -0.08 -0.07 -0.05 -0.02 0 0.01 0.01 ## PACF -0.04 -0.05 0.04 -0.02 -0.02 0 -0.05 0.00 ARMA(1,0) arma&lt;-arima.sim(list(order=c(1,0,0),ar=.6),n=500) acf2(arma) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## ACF 0.59 0.35 0.22 0.19 0.13 0.09 0.04 0.04 0.04 0.03 0.01 -0.01 -0.02 ## PACF 0.59 0.01 0.02 0.08 -0.03 0.00 -0.02 0.03 0.00 -0.01 0.00 -0.03 -0.02 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] ## ACF 0.03 0.03 0.02 0.04 0.05 0.06 0.06 0.05 0.04 0.06 0.02 -0.02 ## PACF 0.09 -0.03 0.00 0.05 0.00 0.03 0.01 0.00 0.00 0.04 -0.05 -0.04 ## [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] ## ACF -0.06 -0.07 -0.07 -0.08 -0.08 -0.06 -0.09 -0.13 ## PACF -0.05 0.00 -0.04 -0.02 0.00 0.01 -0.08 -0.06 ARMA(0,1) arma&lt;-arima.sim(list(order=c(0,0,1),ma=.9),n=500) acf2(arma) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## ACF 0.5 0.03 0.02 -0.01 -0.04 -0.01 0.03 0.03 0.05 0.03 -0.02 -0.02 -0.03 ## PACF 0.5 -0.31 0.23 -0.20 0.11 -0.06 0.08 -0.05 0.10 -0.10 0.05 -0.06 0.02 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] ## ACF -0.03 -0.02 0.00 0.04 0.05 0.00 0.00 0.01 -0.01 -0.04 -0.01 0.06 ## PACF -0.04 0.02 -0.01 0.08 -0.03 -0.01 0.03 -0.02 0.00 -0.04 0.05 0.05 ## [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] ## ACF 0.04 0.00 0.06 0.08 -0.01 -0.05 -0.02 0.03 ## PACF -0.06 0.05 0.05 0.01 -0.06 0.01 0.01 0.05 可以发现，增大样本容量使得PACF，ACF本应有的截尾性质更加显著。 4.5 4.5 cmort数据分析 4.5.1 (a) xt=diff(cmort) tsplot(cmort, main=&quot;Cardiovascular Mortality&quot;, col=6, type=&quot;o&quot;, pch=19, ylab=&quot;&quot;) tsplot(xt, main=&quot;Diff Cardiovascular Mortality&quot;, col=6, type=&quot;o&quot;, pch=19, ylab=&quot;&quot;) 在进行差分后数据更加的接近均值为0的白噪声，并且不再有明显的趋势。因此进行差分是合理的做法。 4.5.2 (b) acf1(xt) pacf(xt) ACF的图像近似为拖尾的，而PACF可以认为是在滞后\\(p=1\\)处截尾，因此由表4.1，AR(1)适用于\\(x_{t}\\)。 4.5.3 (c) # 拟合ARIMA模型 model &lt;- sarima(xt, p = 1, d = 0, q = 0, no.constant = TRUE) #获取回归参数的检验 ttable &lt;- model$ttable # 获取模型的残差标准差 residual_std &lt;- model$fit$sigma2 #显著性检验 cat(&quot;回归参数估计以及相关统计量为：\\n&quot;) ## 回归参数估计以及相关统计量为： ttable ## Estimate SE t.value p.value ## ar1 -0.5064 0.0383 -13.2224 0 由于p-value很小，因此可以AR(1)的回归参数估计是显著的。 # 输出残差标准差 cat(&quot;白噪声方差的估计值为：&quot;, residual_std, &quot;\\n&quot;) ## 白噪声方差的估计值为： 33.81057 4.5.4 (d) sarima(xt, p = 1, d = 0, q = 0, no.constant = TRUE) 利用Normal Q-Q Plot of Std Residuals图来检测残差，可以认为残差为白噪声。 4.5.5 (e) 对未来四个星期进行预测，并计算相应的95%的预测间隔： sarima_result=sarima.for(xt,n.ahead=4,p=1,d=0,q=0) # 提取预测值 forecast_values &lt;- sarima_result$pred # 提取标准误差 se &lt;- sarima_result$se # 计算95%预测间隔的上限和下限 lower_bound &lt;- forecast_values - 2 * se upper_bound &lt;- forecast_values + 2 * se # 输出预测结果和预测间隔 week &lt;- c(&quot;week 1&quot;,&quot;week 2&quot;,&quot;week 3&quot;,&quot;week 4&quot;) result &lt;- data.frame(week,预测值 = forecast_values, 下限 = lower_bound, 上限 = upper_bound) result ## week 预测值 下限 上限 ## 1 week 1 1.9555424 -9.673559 13.58464 ## 2 week 2 -1.0298842 -14.065001 12.00523 ## 3 week 3 0.4818973 -12.889967 13.85376 ## 4 week 4 -0.2836494 -13.740508 13.17321 4.5.6 (f) 首先，预测值是通过运行SARIMA模型的预测函数（例如sarima.for()）得到的。这个函数基于已有的时间序列数据和模型参数，根据模型的推断方法来生成未来时间点的预测值。在例子中，sarima.for()函数返回了一个包含四个预测值的时间序列对象，分别对应未来四个时间点的预测。 然后，标准误差是指模型在预测过程中产生的误差的标准差。它用来度量模型预测的不确定性。在例子中，sarima.for()函数还返回了一个包含四个标准误差值的时间序列对象，分别对应于每个预测值的标准误差。 接下来，根据预测值和标准误差，可以计算出预测区间。预测区间是用来表示预测值的不确定性范围，通常以置信水平的形式给出（如95%置信区间）。在这种情况下，我们可以使用预测值加减两倍标准误差来计算95%的预测区间。下限等于预测值减去两倍的标准误差，上限等于预测值加上两倍的标准误差。 因此，根据结果，预测区间可以通过预测值加减两倍标准误差来计算得到。这个预测区间可以帮助评估预测值的可靠性，并提供对未来观测值可能的范围的一定程度的估计。 4.5.7 (g) 心血管死亡率实际值提前一步预测\\(c_{n+1}^{n}\\)等于 \\[ c_{n+1}^{n}=\\phi c_{n}=-0.5064c_{n} \\] 4.6 4.6 模型预测与MSPE m步预测为 \\[ x_{n+m}^{n}=\\phi^{m}x_{n} \\] 根据课本上的结果及几何级数的和，MSPE为： \\[\\begin{align} E[(x_{n+m}-x_{n+m}^{n})^{2}]&amp;=\\sigma_{w}^{2}(1+\\phi^2+···+\\phi……{2(m-1)})\\notag\\\\ &amp;=\\sigma_{w}^{2}\\frac{1-\\phi^{2m}}{1-\\phi^2}\\notag \\end{align}\\] 4.7 4.7 参数估计 # 重复进行五次实验 num_experiments &lt;- 5 output &lt;- &quot;&quot; # 初始化输出字符串 for (i in 1:num_experiments) { # 生成100个iid N(0,1)观测值并拟合ARMA(1,1)模型 data &lt;- rnorm(100) model &lt;- sarima(data, 1, 0, 1) # 输出参数估计结果 output &lt;- paste(output, &quot;在实验&quot;, i, &quot;中，拟合的ARMA(1,1)模型的参数估计结果为：\\n&quot;) output &lt;- paste(output, &quot;AR 参数估计值:&quot;, model$fit$coef[1],&quot;\\n&quot;) output &lt;- paste(output, &quot;MA 参数估计值:&quot;, model$fit$coef[2],&quot;\\n&quot;) output &lt;- paste(output, &quot;\\n&quot;) } # 输出信息 cat(output) ## 在实验 1 中，拟合的ARMA(1,1)模型的参数估计结果为： ## AR 参数估计值: -0.471503493155923 ## MA 参数估计值: 0.6102172613011 ## ## 在实验 2 中，拟合的ARMA(1,1)模型的参数估计结果为： ## AR 参数估计值: -0.662910634161264 ## MA 参数估计值: 0.583349220329755 ## ## 在实验 3 中，拟合的ARMA(1,1)模型的参数估计结果为： ## AR 参数估计值: 0.532586608641356 ## MA 参数估计值: -0.414304525082842 ## ## 在实验 4 中，拟合的ARMA(1,1)模型的参数估计结果为： ## AR 参数估计值: 0.558430221940262 ## MA 参数估计值: -0.703347009129763 ## ## 在实验 5 中，拟合的ARMA(1,1)模型的参数估计结果为： ## AR 参数估计值: -0.652726392342175 ## MA 参数估计值: 0.922044360823668 ## 4.8 4.8 参数的MLE 生成参数\\(\\phi=0.9, \\theta=0.5, \\sigma^{2}=1\\)的ARMA(1,1)过程的\\(n=200\\)个观测值，重复十次，并且每次都求出三个参数的MLE： set.seed(2023)#使得结果可重现 c()-&gt;phi-&gt;theta-&gt;sigma2 for (i in 1:10) { x = arima.sim(n=200,list(ar=.9,ma=.5)) fit = arima(x, order = c(1,0,1)) phi[i]=fit$coef[1]; theta[i]=fit$coef[2]; sigma2=fit$sigma2 } A=cbind(&quot;phi&quot;=phi,&quot;theta&quot;=theta,&quot;sigma2&quot;=sigma2) A ## phi theta sigma2 ## [1,] 0.9472737 0.4324380 1.026246 ## [2,] 0.8677612 0.4774988 1.026246 ## [3,] 0.8824127 0.5129200 1.026246 ## [4,] 0.9237088 0.4689059 1.026246 ## [5,] 0.9408428 0.3550534 1.026246 ## [6,] 0.8050361 0.5683730 1.026246 ## [7,] 0.9317511 0.4796632 1.026246 ## [8,] 0.9029819 0.4977130 1.026246 ## [9,] 0.9061346 0.5107797 1.026246 ## [10,] 0.9203406 0.5325410 1.026246 可以使用误差值和真实值之间的误差图来对比真实值和误差值： # 真实值 true_phi &lt;- 0.9 true_theta &lt;- 0.5 true_sigma2 &lt;- 1 # 估计值 estimated_phi &lt;- A[,1] estimated_theta &lt;- A[,2] estimated_sigma2 &lt;- A[,3] # 计算误差 error_phi &lt;- estimated_phi - true_phi error_theta &lt;- estimated_theta - true_theta error_sigma2 &lt;- estimated_sigma2 - true_sigma2 # 创建数据框 error_data &lt;- data.frame(index = 1:10, phi = error_phi, theta = error_theta, sigma2 = error_sigma2) # 绘制误差图 ggplot(data = error_data) + geom_line(aes(x = index, y = phi, color = &quot;phi&quot;), size = 1) + geom_line(aes(x = index, y = theta, color = &quot;theta&quot;), size = 1) + geom_line(aes(x = index, y = sigma2, color = &quot;sigma2&quot;), size = 1) + labs(x = &quot;Index&quot;, y = &quot;Error&quot;, title = &quot;Error Plot&quot;) + geom_point(aes(x = index, y = phi, color = &quot;phi&quot;), size = 3) + geom_point(aes(x = index, y = theta, color = &quot;theta&quot;), size = 3) + geom_point(aes(x = index, y = sigma2, color = &quot;sigma2&quot;), size = 3) + labs(x = &quot;Index&quot;, y = &quot;Error&quot;, title = &quot;Error Plot&quot;) + scale_color_manual(values = c(&quot;phi&quot; = &quot;#1f77b4&quot;, &quot;theta&quot; = &quot;#ff7f0e&quot;, &quot;sigma2&quot; = &quot;#2ca02c&quot;),name = &quot;&quot;) + theme_minimal() + theme(legend.position = &quot;top&quot;) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. 可以发现\\(\\sigma^2\\)的误差恒定，\\(\\theta\\)的误差振幅较大。 4.9 4.9 AR(1)的高斯-牛顿算法 AR(1)过程\\(x_{t}=\\phi x_{t-1}+w_{t}\\)其误差为： \\[ w_{t}(\\phi)=x_{t}-\\phi x_{t-1} \\] 其中，\\(x_{t}\\)是时间序列的当前观测值，\\(x_{t-1}\\)是前一时刻的观测值，\\(w_{t}\\)是误差项，\\(\\phi\\)是我们要估计的自回归参数。 高斯-牛顿算法的基本思想是通过迭代寻找使得目标函数达到最小化的参数值。在AR(1)模型中，我们可以将参数估计问题转化为最小化目标函数的问题。 对于AR(1)模型，可以构建似然函数或平方和损失函数作为目标函数。然后，我们使用高斯-牛顿算法的迭代步骤来更新参数值，直到达到收敛条件。在本例中选取 \\[ S_{c}(\\phi)=\\sum_{t=1}^{n}w_{t}^{2}(\\phi) \\] 设\\(\\phi_{0}\\)是\\(\\phi\\)的一个初始估计。\\(S_{c}(\\phi)\\)在\\(\\phi_{0}\\)的一阶泰勒展式为： \\[ S_{c}(\\phi)=\\sum_{t=1}^{n}w_{t}^{2}(\\phi)\\approx \\sum_{t=1}^{n}[w_{t}(\\phi_{0})-(\\phi-\\phi_{0})z_{t}(\\phi_{0})]^{2} \\] 其中， \\[ z_{t}(\\phi_{0})=-\\frac{\\partial w_{\\phi}}{\\partial \\phi}\\mid_{\\phi=\\phi_{0}} \\] 经运算可得 \\[ z_{t}(\\phi_{0})= x_{t-1} \\] 因为算法使用给定的数据\\(x_{1},···,x_{n}\\)，而不考虑任何条件信息。因此高斯-牛顿算法过程产生的估计可以被视为无条件估计。 总结起来，高斯-牛顿算法可以用于估计AR(1)模型中的自回归参数。该算法过程产生的估计是无条件估计，因为它不考虑任何条件信息。 4.10 4.10 预测误差 构造\\(\\Delta\\)如下： \\[\\begin{align} \\Delta&amp;=\\sum_{j=0}^{\\infty}\\phi_{j}w_{m+n-j}^{n}-\\sum_{j=m}^{\\infty}\\phi_{j}w_{m+n-j}\\notag\\\\ &amp;=\\sum_{j=0}^{m-1}\\phi_{j}w_{m+n-j}^{n} + \\sum_{j=m}^{\\infty}\\phi_{j}(w_{m+n-j}^{n}-w_{m+n-j})\\notag \\end{align}\\] 由于时间序列\\(x_{t}\\)可以写成因果和的形式，那么常数\\(\\phi_{j}\\)存在如下约束： \\[ \\sum_{j=0}^{\\infty}\\phi^{2}&lt;\\infty \\] 这表明\\(n\\to\\infty\\)时，\\(\\phi_{j}\\to 0\\)。因此有 \\[ \\sum_{j=0}^{m-1}\\phi_{j}w_{m+n-j}^{n} \\to 0 , n\\to\\infty \\] 当\\(j\\ge m\\)时，\\(w_{n+m-j}^{n}\\)实际上是确定已知的历史数据\\(w_{n+m-j}\\)，因此 \\[ \\sum_{j=m}^{\\infty}\\phi_{j}(w_{m+n-j}^{n}-w_{m+n-j})=0 \\] 综上可知，当\\(n\\to0\\)时，\\(\\Delta\\to0\\)。这表明，当n充分大的时候，有如下结果： \\[ x_{n+m}^{n}=\\sum_{j=0}^{\\infty}\\phi_{j}w_{m+n-j}^{n}=\\sum_{j=m}^{\\infty}\\phi_{j}w_{m+n-j} \\] 利用上面的结果可以证明如下结论： \\[\\begin{align} E[x_{n+m}-x_{n+m}^{n}]^{2}&amp;=E[\\sum_{j=0}^{\\infty}\\phi_{j}w_{m+n-j}-\\sum_{j=m}^{\\infty}\\phi_{j}w_{m+n-j}]\\notag\\\\ &amp;=E[\\sum_{j=0}^{m-1}\\phi_{j}w_{n+m-j}]^{2}\\notag\\\\ &amp;=\\sum_{j=0}^{m-1}\\phi_{j}^{2}E[w_{n+m-j}^{2}]\\notag\\\\ &amp;=\\sigma^{2}_{w}\\sum_{j=0}^{m-1}\\phi_{j}^{2}\\notag \\end{align}\\] \\(\\square\\) "],["第五章作业.html", "Chapter 5 第五章作业 Libs 5.1 5.1 5.2 5.2 5.3 5.3 5.4 5.4 5.5 5.5 5.6 5.6 5.7 5.7 5.8 5.8 5.9 5.9 5.10 5.10 5.11 5.11 5.12 5.12", " Chapter 5 第五章作业 Libs pacman::p_load(astsa,tidyverse,ggplot2,reshape2,forecast,grid) 5.1 5.1 x &lt;- log(varve[1:100]) x25 &lt;- HoltWinters(x, alpha = 0.75, beta = FALSE, gamma = FALSE) x50 &lt;- HoltWinters(x, alpha = 0.50, beta = FALSE, gamma = FALSE) x75 &lt;- HoltWinters(x, alpha = 0.25, beta = FALSE, gamma = FALSE) x25_fit &lt;- x25$fit[, 1] x50_fit &lt;- x50$fit[, 1] x75_fit &lt;- x75$fit[, 1] df &lt;- data.frame( x = seq_along(x)[1:length(x)-1], y = x[1:length(x)-1], x25 = x25_fit, x50 = x50_fit, x75 = x75_fit ) ggplot(df, aes(x = x, y = y)) + geom_point(color = &quot;black&quot;, shape = 1) + geom_line(aes(y = y), color = &quot;darkgray&quot; )+ geom_line(aes(y = x25, color = &quot;0.25&quot;), linetype = &quot;solid&quot;) + geom_line(aes(y = x50, color = &quot;0.50&quot;), linetype = &quot;solid&quot;) + geom_line(aes(y = x75, color = &quot;0.75&quot;), linetype = &quot;solid&quot;) + labs(ylab = &quot;log(varve)&quot;) 5.2 5.2 layout(1:2, heights=2:1) tsplot(gdp, col=4) acf2(gdp) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## ACF 0.99 0.98 0.97 0.96 0.95 0.94 0.93 0.92 0.91 0.90 0.89 0.88 0.87 ## PACF 0.99 0.00 0.00 -0.01 0.00 0.00 0.00 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] ## ACF 0.86 0.85 0.84 0.83 0.82 0.81 0.80 0.79 0.78 0.77 0.76 0.75 ## PACF -0.01 0.00 0.00 -0.01 0.00 0.00 -0.02 0.00 0.00 -0.01 0.00 -0.01 ## [,26] [,27] ## ACF 0.74 0.73 ## PACF -0.01 -0.01 dev.new() tsplot(diff(log(gdp)), ylab=&quot;GNP Growth Rate&quot;, col=4) abline(h = mean(diff(log(gdp))), col=6) dev.new() acf2(diff(log(gdp)), main=&quot;&quot;) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] ## ACF 0.36 0.23 0.02 -0.06 -0.13 -0.03 -0.04 -0.01 0.08 0.10 0.02 -0.11 -0.11 ## PACF 0.36 0.11 -0.11 -0.07 -0.08 0.07 -0.02 -0.02 0.10 0.04 -0.07 -0.16 -0.02 ## [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] ## ACF -0.05 -0.08 0.05 0.05 0.11 0.07 0.07 -0.07 -0.05 -0.09 -0.02 0.03 ## PACF 0.08 -0.06 0.08 0.01 0.06 -0.02 -0.01 -0.07 0.03 -0.04 0.03 0.05 ## [,26] [,27] ## ACF 0.03 0.06 ## PACF -0.04 0.03 ## sarima(diff(log(gdp)), 3,0,0) # AR(3) on growth rate ## initial value -4.672826 ## iter 2 value -4.735845 ## iter 3 value -4.756484 ## iter 4 value -4.756533 ## iter 5 value -4.756533 ## iter 6 value -4.756533 ## iter 6 value -4.756533 ## iter 6 value -4.756533 ## final value -4.756533 ## converged ## initial value -4.754958 ## iter 2 value -4.754969 ## iter 3 value -4.754970 ## iter 4 value -4.754973 ## iter 5 value -4.754973 ## iter 5 value -4.754973 ## iter 5 value -4.754973 ## final value -4.754973 ## converged ## $fit ## ## Call: ## arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), ## xreg = xmean, include.mean = FALSE, transform.pars = trans, fixed = fixed, ## optim.control = list(trace = trc, REPORT = 1, reltol = tol)) ## ## Coefficients: ## ar1 ar2 ar3 xmean ## 0.3331 0.1489 -0.1122 0.0077 ## s.e. 0.0587 0.0613 0.0588 0.0008 ## ## sigma^2 estimated as 7.406e-05: log likelihood = 954.11, aic = -1898.21 ## ## $degrees_of_freedom ## [1] 282 ## ## $ttable ## Estimate SE t.value p.value ## ar1 0.3331 0.0587 5.6759 0.0000 ## ar2 0.1489 0.0613 2.4283 0.0158 ## ar3 -0.1122 0.0588 -1.9069 0.0575 ## xmean 0.0077 0.0008 9.5617 0.0000 ## ## $AIC ## [1] -6.637105 ## ## $AICc ## [1] -6.636607 ## ## $BIC ## [1] -6.573189 sarima(diff(log(gdp)), 0,0,1) # MA(1) on growth rate ## initial value -4.672758 ## iter 2 value -4.716609 ## iter 3 value -4.723220 ## iter 4 value -4.723481 ## iter 5 value -4.723483 ## iter 5 value -4.723483 ## iter 5 value -4.723483 ## final value -4.723483 ## converged ## initial value -4.723444 ## iter 1 value -4.723444 ## final value -4.723444 ## converged ## $fit ## ## Call: ## arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), ## xreg = xmean, include.mean = FALSE, transform.pars = trans, fixed = fixed, ## optim.control = list(trace = trc, REPORT = 1, reltol = tol)) ## ## Coefficients: ## ma1 xmean ## 0.2687 0.0077 ## s.e. 0.0470 0.0007 ## ## sigma^2 estimated as 7.891e-05: log likelihood = 945.09, aic = -1884.18 ## ## $degrees_of_freedom ## [1] 284 ## ## $ttable ## Estimate SE t.value p.value ## ma1 0.2687 0.0470 5.7155 0 ## xmean 0.0077 0.0007 11.5865 0 ## ## $AIC ## [1] -6.588031 ## ## $AICc ## [1] -6.587883 ## ## $BIC ## [1] -6.549682 # round( ARMAtoMA(ar=.33, ma=0, 10), 3) # print psi-weights ## [1] 0.330 0.109 0.036 0.012 0.004 0.001 0.000 0.000 0.000 0.000 从Ljung-Box统计量的检验结果来看，AR(3)模型也具有较好的残差性质。 从AIC，AICc，BIC的角度看（越小越好），因此更加倾向于AR(3)模型。 因此，综合考虑起来，对于差分后的数据选择模型AR(3)，那么对于原始数据，选择的模型为ARIMA(3,1,0)。 5.3 5.3 auto.arima(oil) ## Series: oil ## ARIMA(1,1,3)(0,0,1)[52] ## ## Coefficients: ## ar1 ma1 ma2 ma3 sma1 ## 0.8793 -0.725 -0.1178 0.066 -0.0738 ## s.e. 0.0539 0.069 0.0552 0.044 0.0436 ## ## sigma^2 = 6.396: log likelihood = -1274.33 ## AIC=2560.66 AICc=2560.82 BIC=2586.46 acf2(oil) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## ACF 0.99 0.99 0.98 0.97 0.95 0.94 0.93 0.92 0.90 0.89 0.87 0.86 ## PACF 0.99 -0.17 -0.04 -0.10 0.00 -0.04 -0.03 -0.01 -0.14 -0.03 -0.04 -0.02 ## [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] ## ACF 0.84 0.82 0.81 0.79 0.77 0.76 0.74 0.72 0.71 0.69 0.68 0.66 ## PACF -0.01 0.05 -0.05 0.00 0.06 -0.04 -0.04 0.02 0.09 0.05 -0.04 0.04 ## [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] ## ACF 0.65 0.64 0.63 0.61 0.61 0.59 0.59 0.58 0.57 0.56 0.55 0.55 ## PACF 0.00 0.10 -0.02 0.11 -0.02 -0.06 0.00 0.03 0.04 0.00 -0.02 0.06 ## [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] ## ACF 0.54 0.54 0.53 0.53 0.52 0.52 0.51 0.51 0.51 0.50 0.50 0.50 ## PACF -0.03 0.01 -0.04 -0.01 0.02 0.04 0.05 -0.01 -0.03 -0.06 -0.02 -0.01 ## [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] ## ACF 0.49 0.49 0.48 0.48 0.48 0.47 0.47 0.47 0.47 0.47 0.47 0.47 ## PACF 0.00 0.00 0.01 0.04 0.09 0.02 0.04 0.00 0.02 0.11 0.00 0.05 ## [,61] [,62] [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] ## ACF 0.47 0.47 0.47 0.47 0.47 0.48 0.48 0.48 0.48 0.48 0.49 0.49 ## PACF -0.04 0.05 -0.03 0.03 0.01 0.01 -0.08 -0.04 0.04 0.06 0.01 -0.06 ## [,73] [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] ## ACF 0.49 0.50 0.50 0.50 0.51 0.51 0.51 0.51 0.51 0.51 0.52 0.52 ## PACF 0.06 0.04 -0.01 -0.02 0.02 0.00 -0.03 -0.05 -0.01 0.02 0.02 -0.07 ## [,85] [,86] [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] ## ACF 0.52 0.52 0.51 0.51 0.51 0.51 0.51 0.51 0.5 0.50 0.49 0.49 ## PACF 0.02 0.01 -0.06 0.02 0.03 0.03 -0.02 0.03 0.0 -0.08 0.03 -0.03 ## [,97] [,98] [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] ## ACF 0.48 0.48 0.47 0.46 0.46 0.45 0.44 0.44 0.43 0.42 0.41 ## PACF -0.05 0.01 -0.03 -0.02 -0.03 0.03 0.02 0.01 -0.03 0.02 0.01 ## [,108] [,109] [,110] [,111] [,112] [,113] [,114] [,115] [,116] [,117] ## ACF 0.41 0.40 0.39 0.38 0.38 0.37 0.36 0.35 0.34 0.33 ## PACF 0.01 -0.05 -0.04 -0.01 -0.02 -0.03 -0.02 -0.03 0.04 0.01 ## [,118] [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126] [,127] ## ACF 0.32 0.31 0.31 0.30 0.29 0.28 0.27 0.26 0.26 0.25 ## PACF 0.00 0.01 -0.02 -0.05 -0.03 0.02 -0.02 0.00 0.05 0.01 ## [,128] [,129] [,130] [,131] [,132] [,133] [,134] [,135] [,136] [,137] ## ACF 0.24 0.24 0.23 0.22 0.21 0.20 0.20 0.19 0.18 0.18 ## PACF -0.04 -0.01 -0.04 -0.04 0.05 -0.01 0.01 -0.02 -0.01 0.01 ## [,138] [,139] [,140] [,141] [,142] [,143] [,144] [,145] [,146] [,147] ## ACF 0.17 0.17 0.16 0.16 0.15 0.15 0.14 0.14 0.14 0.13 ## PACF 0.04 -0.03 -0.01 -0.01 -0.01 -0.03 -0.01 -0.01 -0.03 0.00 ## [,148] [,149] [,150] [,151] [,152] [,153] [,154] [,155] [,156] [,157] ## ACF 0.13 0.12 0.12 0.11 0.11 0.10 0.10 0.09 0.09 0.08 ## PACF -0.03 -0.02 -0.02 -0.02 -0.03 -0.02 -0.03 -0.04 0.01 -0.01 ## [,158] [,159] [,160] [,161] [,162] [,163] [,164] [,165] [,166] [,167] ## ACF 0.08 0.08 0.07 0.07 0.06 0.06 0.05 0.05 0.04 0.04 ## PACF 0.01 0.06 -0.01 -0.03 0.01 -0.02 -0.01 0.03 -0.02 0.00 ## [,168] [,169] [,170] [,171] [,172] [,173] [,174] [,175] [,176] [,177] ## ACF 0.03 0.03 0.02 0.02 0.01 0.01 0.01 0 0 0.00 ## PACF 0.01 0.00 -0.02 -0.02 0.01 -0.01 -0.01 0 0 -0.03 ## [,178] [,179] [,180] [,181] [,182] [,183] [,184] [,185] [,186] [,187] ## ACF -0.01 -0.01 -0.02 -0.02 -0.02 -0.03 -0.03 -0.03 -0.04 -0.04 ## PACF -0.03 0.00 0.04 -0.01 -0.01 -0.05 0.01 -0.02 -0.01 0.01 ## [,188] [,189] [,190] [,191] [,192] [,193] [,194] [,195] [,196] [,197] ## ACF -0.04 -0.05 -0.05 -0.05 -0.06 -0.06 -0.07 -0.07 -0.07 -0.08 ## PACF -0.02 0.01 0.03 0.03 -0.02 -0.02 -0.03 -0.01 -0.01 -0.06 ## [,198] [,199] [,200] [,201] [,202] [,203] [,204] [,205] [,206] [,207] ## ACF -0.08 -0.09 -0.09 -0.10 -0.10 -0.11 -0.11 -0.12 -0.12 -0.13 ## PACF 0.00 0.02 0.01 0.01 -0.02 -0.02 0.03 0.03 -0.04 -0.03 ## [,208] ## ACF -0.13 ## PACF -0.01 sarima(oil,0,0,3) ## initial value 3.253470 ## iter 2 value 2.397818 ## iter 3 value 2.377181 ## iter 4 value 2.002749 ## iter 5 value 1.893578 ## iter 6 value 1.886120 ## iter 7 value 1.885091 ## iter 8 value 1.882875 ## iter 9 value 1.881364 ## iter 10 value 1.880891 ## iter 11 value 1.871508 ## iter 12 value 1.868136 ## iter 13 value 1.867923 ## iter 14 value 1.867667 ## iter 15 value 1.867605 ## iter 16 value 1.867504 ## iter 17 value 1.867486 ## iter 18 value 1.867482 ## iter 19 value 1.867482 ## iter 19 value 1.867482 ## final value 1.867482 ## converged ## initial value 1.839929 ## iter 2 value 1.838516 ## iter 3 value 1.837368 ## iter 4 value 1.835647 ## iter 5 value 1.835029 ## iter 6 value 1.833975 ## iter 7 value 1.833785 ## iter 8 value 1.833762 ## iter 9 value 1.833761 ## iter 9 value 1.833761 ## iter 9 value 1.833761 ## final value 1.833761 ## converged ## $fit ## ## Call: ## arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), ## xreg = xmean, include.mean = FALSE, transform.pars = trans, fixed = fixed, ## optim.control = list(trace = trc, REPORT = 1, reltol = tol)) ## ## Coefficients: ## ma1 ma2 ma3 xmean ## 1.6231 1.5291 0.7605 52.0373 ## s.e. 0.0259 0.0298 0.0224 1.3080 ## ## sigma^2 estimated as 38.84: log likelihood = -1772.72, aic = 3555.44 ## ## $degrees_of_freedom ## [1] 541 ## ## $ttable ## Estimate SE t.value p.value ## ma1 1.6231 0.0259 62.7615 0 ## ma2 1.5291 0.0298 51.2346 0 ## ma3 0.7605 0.0224 33.9465 0 ## xmean 52.0373 1.3080 39.7833 0 ## ## $AIC ## [1] 6.523747 ## ## $AICc ## [1] 6.523883 ## ## $BIC ## [1] 6.563204 5.4 5.4 gtemp_land ## Time Series: ## Start = 1880 ## End = 2021 ## Frequency = 1 ## [1] -0.60 -0.39 -0.49 -0.58 -0.75 -0.76 -0.60 -0.69 -0.54 -0.26 -0.52 -0.45 ## [13] -0.52 -0.51 -0.41 -0.40 -0.37 -0.19 -0.33 -0.12 -0.02 -0.03 -0.22 -0.23 ## [25] -0.36 -0.18 -0.09 -0.53 -0.32 -0.37 -0.30 -0.38 -0.42 -0.25 0.01 -0.05 ## [37] -0.42 -0.62 -0.45 -0.29 -0.29 -0.03 -0.23 -0.20 -0.20 -0.09 0.06 -0.15 ## [49] -0.01 -0.42 -0.02 0.09 0.06 -0.26 0.05 -0.10 -0.05 0.04 0.26 0.18 ## [61] 0.13 0.14 0.08 0.11 0.20 -0.08 0.04 0.14 0.09 -0.03 -0.28 -0.08 ## [73] -0.01 0.24 -0.10 -0.07 -0.37 0.02 0.10 0.06 -0.09 0.14 0.08 0.17 ## [85] -0.27 -0.13 -0.05 0.02 -0.14 -0.13 0.03 -0.03 -0.15 0.31 -0.13 0.13 ## [97] -0.25 0.23 0.05 0.11 0.33 0.53 0.06 0.42 0.09 0.05 0.25 0.38 ## [109] 0.61 0.33 0.66 0.57 0.25 0.23 0.46 0.74 0.39 0.58 0.91 0.68 ## [121] 0.60 0.79 0.98 0.90 0.75 1.08 0.93 1.17 0.86 0.93 1.10 0.95 ## [133] 0.96 1.03 1.00 1.29 1.46 1.35 1.20 1.40 1.56 1.29 auto.arima(gtemp_land) ## Series: gtemp_land ## ARIMA(0,1,1) with drift ## ## Coefficients: ## ma1 drift ## -0.7023 0.0139 ## s.e. 0.0601 0.0044 ## ## sigma^2 = 0.03049: log likelihood = 46.68 ## AIC=-87.35 AICc=-87.18 BIC=-78.51 tsplot(gtemp_land) acf2(diff(gtemp_land)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## ACF -0.41 -0.01 -0.17 0.18 -0.08 -0.01 -0.02 0.13 -0.16 0.17 -0.09 0.02 ## PACF -0.41 -0.22 -0.33 -0.08 -0.11 -0.13 -0.10 0.05 -0.13 0.11 0.05 -0.01 ## [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] ## ACF -0.05 0.03 0.06 -0.10 0.04 0.08 -0.14 0.12 -0.08 0.15 ## PACF 0.03 -0.02 0.07 -0.05 0.01 0.09 -0.10 0.07 0.00 0.13 sarima(gtemp_land,0,1,1) ## initial value -1.579037 ## iter 2 value -1.707300 ## iter 3 value -1.730190 ## iter 4 value -1.744969 ## iter 5 value -1.749548 ## iter 6 value -1.751354 ## iter 7 value -1.751897 ## iter 8 value -1.752066 ## iter 9 value -1.752339 ## iter 10 value -1.752344 ## iter 11 value -1.752344 ## iter 11 value -1.752344 ## final value -1.752344 ## converged ## initial value -1.749940 ## iter 2 value -1.749961 ## iter 3 value -1.749966 ## iter 4 value -1.749973 ## iter 4 value -1.749973 ## iter 4 value -1.749973 ## final value -1.749973 ## converged ## $fit ## ## Call: ## arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), ## xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, ## REPORT = 1, reltol = tol)) ## ## Coefficients: ## ma1 constant ## -0.7023 0.0139 ## s.e. 0.0601 0.0044 ## ## sigma^2 estimated as 0.03005: log likelihood = 46.68, aic = -87.35 ## ## $degrees_of_freedom ## [1] 139 ## ## $ttable ## Estimate SE t.value p.value ## ma1 -0.7023 0.0601 -11.6793 0.0000 ## constant 0.0139 0.0044 3.1382 0.0021 ## ## $AIC ## [1] -0.6195152 ## ## $AICc ## [1] -0.6188985 ## ## $BIC ## [1] -0.5567756 5.5 5.5 gtemp_ocean ## Time Series: ## Start = 1880 ## End = 2021 ## Frequency = 1 ## [1] -0.05 0.01 0.00 -0.06 -0.15 -0.21 -0.21 -0.24 -0.05 -0.04 -0.29 -0.13 ## [13] -0.18 -0.23 -0.26 -0.14 0.00 -0.05 -0.23 -0.16 -0.07 -0.18 -0.26 -0.41 ## [25] -0.51 -0.28 -0.26 -0.32 -0.47 -0.52 -0.49 -0.47 -0.31 -0.37 -0.21 -0.14 ## [37] -0.33 -0.38 -0.22 -0.27 -0.26 -0.24 -0.30 -0.30 -0.30 -0.26 -0.17 -0.23 ## [49] -0.28 -0.33 -0.19 -0.16 -0.24 -0.29 -0.22 -0.23 -0.19 -0.09 -0.17 -0.09 ## [61] 0.11 0.25 0.05 0.03 0.21 0.19 -0.10 -0.13 -0.17 -0.13 -0.14 -0.05 ## [73] 0.02 0.01 -0.17 -0.19 -0.14 0.05 0.07 0.01 0.00 0.03 0.02 0.03 ## [85] -0.13 -0.09 -0.04 -0.06 -0.04 0.14 0.02 -0.12 0.08 0.10 -0.07 -0.09 ## [97] -0.03 0.14 0.08 0.21 0.23 0.18 0.19 0.26 0.16 0.12 0.16 0.32 ## [109] 0.27 0.22 0.33 0.29 0.22 0.22 0.24 0.28 0.24 0.39 0.44 0.23 ## [121] 0.25 0.38 0.42 0.44 0.43 0.43 0.43 0.34 0.33 0.47 0.47 0.35 ## [133] 0.42 0.46 0.55 0.68 0.70 0.64 0.60 0.68 0.67 0.56 auto.arima(gtemp_ocean) ## Series: gtemp_ocean ## ARIMA(1,1,3) ## ## Coefficients: ## ar1 ma1 ma2 ma3 ## -0.9258 0.9190 -0.5010 -0.5120 ## s.e. 0.0554 0.0912 0.0906 0.0803 ## ## sigma^2 = 0.007738: log likelihood = 144.29 ## AIC=-278.59 AICc=-278.14 BIC=-263.84 tsplot(gtemp_ocean) acf2(diff(gtemp_ocean)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## ACF -0.04 -0.44 0.01 0.14 -0.06 -0.07 0.03 0.05 -0.11 0.05 0.04 -0.07 ## PACF -0.04 -0.44 -0.03 -0.07 -0.09 -0.05 -0.04 0.01 -0.14 0.07 -0.07 -0.03 ## [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] ## ACF -0.06 0.09 -0.03 -0.05 -0.03 0.18 0.06 -0.12 0.05 0.03 ## PACF -0.07 0.03 -0.10 -0.01 -0.10 0.16 0.05 0.03 0.13 -0.03 sarima(gtemp_land,1,1,3) ## initial value -1.578713 ## iter 2 value -1.703207 ## iter 3 value -1.717012 ## iter 4 value -1.735429 ## iter 5 value -1.746726 ## iter 6 value -1.751436 ## iter 7 value -1.751677 ## iter 8 value -1.752187 ## iter 9 value -1.753434 ## iter 10 value -1.757103 ## iter 11 value -1.757729 ## iter 12 value -1.758429 ## iter 13 value -1.758949 ## iter 14 value -1.759725 ## iter 15 value -1.759875 ## iter 16 value -1.759939 ## iter 17 value -1.760158 ## iter 18 value -1.760161 ## iter 19 value -1.760163 ## iter 20 value -1.760168 ## iter 21 value -1.760170 ## iter 22 value -1.760171 ## iter 23 value -1.760171 ## iter 23 value -1.760171 ## final value -1.760171 ## converged ## initial value -1.763590 ## iter 2 value -1.763605 ## iter 3 value -1.763621 ## iter 4 value -1.763647 ## iter 5 value -1.763686 ## iter 6 value -1.763755 ## iter 7 value -1.763972 ## iter 8 value -1.764121 ## iter 9 value -1.764311 ## iter 10 value -1.764348 ## iter 11 value -1.764350 ## iter 12 value -1.764351 ## iter 12 value -1.764351 ## final value -1.764351 ## converged ## $fit ## ## Call: ## arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), ## xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, ## REPORT = 1, reltol = tol)) ## ## Coefficients: ## ar1 ma1 ma2 ma3 constant ## -0.9176 0.3081 -0.6233 -0.1471 0.0138 ## s.e. 0.1037 0.1293 0.1012 0.0827 0.0041 ## ## sigma^2 estimated as 0.02919: log likelihood = 48.7, aic = -85.41 ## ## $degrees_of_freedom ## [1] 136 ## ## $ttable ## Estimate SE t.value p.value ## ar1 -0.9176 0.1037 -8.8486 0.0000 ## ma1 0.3081 0.1293 2.3823 0.0186 ## ma2 -0.6233 0.1012 -6.1578 0.0000 ## ma3 -0.1471 0.0827 -1.7787 0.0775 ## constant 0.0138 0.0041 3.3451 0.0011 ## ## $AIC ## [1] -0.6057187 ## ## $AICc ## [1] -0.6025666 ## ## $BIC ## [1] -0.4802395 5.6 5.6 so2 ## Time Series: ## Start = c(1970, 1) ## End = c(1979, 40) ## Frequency = 52 ## [1] 3.37 2.59 3.29 3.04 3.39 2.57 2.35 3.38 1.50 2.56 3.04 2.64 5.14 2.87 3.54 ## [16] 2.67 1.55 2.93 3.64 5.91 3.69 4.30 3.97 4.98 5.64 3.99 4.20 4.48 3.96 3.65 ## [31] 4.91 4.26 4.02 2.95 3.73 2.02 4.98 3.05 3.73 3.53 2.24 3.03 2.81 2.00 2.27 ## [46] 2.90 3.31 3.44 3.13 4.42 3.60 4.86 1.79 2.95 3.64 2.79 3.77 3.25 4.78 3.37 ## [61] 2.24 2.00 2.78 2.38 3.27 2.82 2.23 1.95 2.57 4.94 3.45 2.83 4.75 3.49 3.84 ## [76] 4.08 6.49 4.05 3.12 4.83 3.35 6.53 3.10 3.53 2.34 6.57 4.07 3.62 1.92 6.04 ## [91] 3.92 3.11 3.77 3.05 2.84 4.19 1.93 3.36 5.92 5.49 4.97 2.53 3.98 3.15 5.44 ## [106] 4.92 4.90 4.82 4.48 3.89 3.75 4.02 2.78 2.64 4.97 2.46 4.57 1.97 2.49 3.49 ## [121] 2.53 3.32 2.26 4.78 5.33 3.46 2.85 5.08 3.65 2.86 2.75 3.05 3.15 2.44 3.87 ## [136] 2.59 3.72 2.67 1.98 4.30 2.95 3.96 2.82 2.66 3.22 3.60 1.92 3.05 3.32 3.42 ## [151] 2.24 3.51 1.93 2.97 2.02 2.20 2.73 2.14 2.11 1.79 2.43 2.08 2.25 2.16 3.28 ## [166] 2.22 3.06 2.41 3.41 2.43 3.76 2.48 4.27 1.70 4.72 4.93 4.57 3.20 4.24 4.73 ## [181] 4.10 3.75 5.91 3.85 2.78 2.60 3.23 4.05 3.95 3.46 4.43 3.85 4.01 2.93 5.65 ## [196] 1.86 2.92 3.44 3.30 3.64 3.10 2.25 1.10 2.39 2.76 3.26 3.26 2.79 3.20 2.15 ## [211] 2.71 2.00 3.70 1.51 2.24 1.94 2.30 2.49 2.48 2.20 2.26 1.85 2.76 2.26 2.57 ## [226] 2.55 4.26 3.84 1.79 2.55 3.02 2.53 2.49 1.86 2.22 2.90 3.39 3.83 2.70 4.59 ## [241] 2.49 2.33 2.46 3.90 1.97 2.44 2.47 3.75 3.46 4.54 2.89 3.68 4.21 1.81 3.18 ## [256] 2.76 4.66 4.65 1.85 3.22 2.80 2.43 6.06 1.85 2.16 2.70 2.05 2.00 1.50 2.72 ## [271] 2.19 2.51 3.09 2.15 2.45 2.68 2.28 2.35 1.73 3.27 2.39 3.43 1.88 3.34 2.76 ## [286] 4.28 2.41 2.88 3.06 4.01 2.23 3.52 3.13 3.86 1.72 2.76 1.77 3.88 3.65 3.64 ## [301] 3.18 2.30 4.12 2.75 4.60 3.13 2.48 3.62 3.50 2.76 4.33 1.20 1.90 1.74 2.81 ## [316] 1.40 2.91 3.77 1.86 1.78 1.39 1.51 1.52 2.89 1.54 3.55 1.19 1.74 1.57 1.63 ## [331] 2.29 3.61 2.35 3.10 1.27 3.02 1.95 2.16 2.04 1.69 3.61 2.85 1.68 1.73 1.56 ## [346] 1.49 2.92 2.43 1.45 2.75 3.00 2.51 3.60 2.78 3.00 3.13 2.91 2.72 2.42 1.67 ## [361] 2.81 3.52 2.63 3.33 3.73 4.07 1.07 1.85 2.12 2.03 1.60 1.69 2.77 2.43 3.78 ## [376] 2.33 1.46 1.26 2.43 1.92 4.19 1.69 2.21 3.24 2.75 3.03 3.18 3.13 3.56 2.78 ## [391] 3.27 2.76 2.27 2.18 3.48 1.36 2.29 2.35 2.92 3.24 2.24 2.94 1.91 3.14 2.94 ## [406] 2.19 4.51 4.16 2.87 1.12 1.67 1.29 1.54 1.76 3.03 2.29 1.17 1.75 2.36 1.12 ## [421] 1.86 2.00 2.22 1.84 2.09 1.91 2.51 2.09 2.10 3.28 2.53 2.38 1.79 2.69 2.21 ## [436] 2.64 1.85 2.07 3.34 2.83 2.43 2.44 1.42 2.47 2.09 2.99 1.58 1.52 1.78 3.19 ## [451] 1.76 3.22 1.66 2.26 2.43 1.86 2.39 1.25 2.53 1.74 2.36 3.13 2.39 1.89 1.59 ## [466] 1.42 1.65 1.12 4.03 1.53 1.41 1.48 2.31 1.24 1.38 1.33 1.42 1.56 1.93 1.51 ## [481] 1.16 1.39 1.62 1.29 0.86 1.59 1.90 1.60 2.01 1.79 1.90 2.08 2.28 2.23 2.31 ## [496] 1.50 2.31 1.65 2.55 2.83 2.05 1.57 2.28 1.72 1.49 1.89 1.63 1.58 #auto.arima(so2) tsplot(so2) acf2(diff(so2)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## ACF -0.54 0.13 -0.15 0.09 -0.02 0.00 -0.03 0.05 -0.05 0.09 -0.11 0.03 ## PACF -0.54 -0.24 -0.28 -0.19 -0.12 -0.11 -0.12 -0.04 -0.07 0.05 -0.01 -0.06 ## [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] ## ACF 0.05 -0.07 0.06 -0.08 0.08 -0.05 0.07 -0.06 0.04 -0.11 0.14 -0.11 ## PACF 0.05 -0.04 -0.01 -0.09 -0.06 -0.08 0.00 -0.03 0.01 -0.13 -0.03 -0.06 ## [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] ## ACF 0.10 -0.07 0.06 -0.05 -0.01 0.04 -0.03 -0.01 0.02 -0.01 0.03 0.00 ## PACF -0.02 -0.01 0.02 0.01 -0.05 0.02 0.00 -0.03 -0.02 -0.02 0.01 0.03 ## [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] ## ACF -0.06 0.08 -0.08 0.11 -0.17 0.14 -0.05 -0.01 0.03 -0.06 0.03 0.02 ## PACF -0.07 -0.02 -0.06 0.02 -0.11 -0.06 -0.02 -0.10 -0.01 -0.09 -0.07 -0.04 ## [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] ## ACF -0.03 0.01 0.04 -0.04 0.02 -0.07 0.13 -0.08 -0.02 0.10 -0.09 0.03 ## PACF -0.04 -0.08 0.04 0.00 0.00 -0.06 0.04 0.06 -0.09 0.09 0.00 -0.02 ## [,61] [,62] [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] ## ACF -0.01 -0.01 0.04 -0.08 0.04 0.02 -0.02 0.03 -0.01 -0.03 0.07 -0.09 ## PACF -0.02 -0.02 -0.01 -0.05 -0.10 -0.03 -0.02 -0.05 0.04 -0.06 0.08 -0.01 ## [,73] [,74] [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] ## ACF 0.05 -0.05 0.06 -0.01 -0.02 0.05 -0.11 0.08 0.01 -0.06 0.08 -0.08 ## PACF 0.00 -0.05 -0.02 0.01 0.01 0.05 -0.07 -0.02 0.01 -0.07 0.03 -0.02 ## [,85] [,86] [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] ## ACF 0.08 -0.07 0.05 -0.02 -0.02 0.05 -0.03 -0.01 0.03 -0.02 0.03 -0.03 ## PACF -0.02 -0.04 0.00 -0.02 -0.05 -0.01 -0.01 -0.01 -0.01 -0.01 0.02 0.01 ## [,97] [,98] [,99] [,100] [,101] [,102] [,103] [,104] [,105] [,106] [,107] ## ACF -0.03 0.04 0.02 -0.02 0.01 -0.03 0.04 -0.04 0.04 -0.02 0.00 ## PACF -0.04 -0.07 0.06 -0.06 -0.01 -0.03 -0.02 -0.03 0.01 0.00 0.03 ## [,108] [,109] [,110] [,111] [,112] [,113] [,114] [,115] [,116] [,117] ## ACF -0.02 0.04 -0.05 0.05 -0.09 0.13 -0.09 0.05 -0.02 -0.03 ## PACF -0.03 0.04 -0.01 -0.02 -0.02 0.00 0.00 0.04 0.03 -0.03 ## [,118] [,119] [,120] [,121] [,122] [,123] [,124] [,125] [,126] [,127] ## ACF 0.10 -0.09 0.01 0.01 -0.03 0.06 -0.09 0.10 -0.06 0.00 ## PACF 0.08 0.05 -0.02 0.04 -0.03 0.02 -0.07 0.04 -0.03 -0.02 ## [,128] [,129] [,130] [,131] [,132] [,133] [,134] [,135] [,136] [,137] ## ACF 0.02 0.04 -0.08 0.04 0.01 0.00 -0.04 0.04 -0.01 0.00 ## PACF -0.01 0.12 0.00 0.02 0.05 0.01 -0.04 -0.01 -0.04 -0.02 ## [,138] [,139] [,140] [,141] [,142] [,143] [,144] [,145] [,146] [,147] ## ACF 0.06 -0.06 -0.06 0.10 -0.04 0.01 -0.02 0.00 0.04 -0.06 ## PACF 0.03 0.03 -0.08 -0.02 0.01 -0.03 -0.01 -0.01 0.01 0.00 ## [,148] [,149] [,150] [,151] [,152] [,153] [,154] [,155] [,156] [,157] ## ACF 0.03 -0.01 0.00 0.02 0.00 0.00 0.02 -0.06 0.05 -0.06 ## PACF -0.05 -0.03 -0.02 -0.03 0.01 0.04 0.05 0.00 -0.08 -0.07 ## [,158] [,159] [,160] [,161] [,162] [,163] [,164] [,165] [,166] [,167] ## ACF 0.14 -0.10 0.01 -0.01 0.00 0.00 0.02 -0.01 -0.06 0.06 ## PACF 0.06 0.09 0.00 -0.01 -0.01 -0.02 0.05 0.06 -0.04 -0.02 ## [,168] [,169] [,170] [,171] [,172] [,173] [,174] [,175] [,176] [,177] ## ACF 0.01 -0.03 0.01 0.04 -0.08 0.06 -0.08 0.08 -0.02 0.03 ## PACF 0.01 -0.01 0.01 0.03 -0.02 0.02 -0.05 0.04 -0.05 0.00 ## [,178] [,179] [,180] [,181] [,182] [,183] [,184] [,185] [,186] [,187] ## ACF -0.04 -0.02 0.02 0.04 -0.03 0.01 -0.01 -0.06 0.08 -0.03 ## PACF 0.02 -0.03 -0.07 -0.02 0.06 0.02 0.01 -0.04 0.00 0.04 ## [,188] [,189] [,190] [,191] [,192] [,193] [,194] [,195] [,196] [,197] ## ACF -0.03 0.03 0.00 -0.01 -0.03 0.04 0.05 -0.10 0.09 -0.11 ## PACF -0.05 0.00 0.02 0.02 -0.07 -0.02 0.01 0.02 -0.01 -0.06 ## [,198] [,199] [,200] [,201] [,202] [,203] [,204] [,205] [,206] [,207] ## ACF 0.10 -0.07 0.10 -0.08 0.03 -0.02 0.04 -0.08 0.07 -0.04 ## PACF -0.03 -0.07 0.04 0.00 0.04 0.00 0.05 -0.03 0.00 -0.02 ## [,208] ## ACF 0.04 ## PACF -0.01 sarima(so2,2,1,3) ## initial value 0.162245 ## iter 2 value 0.021810 ## iter 3 value -0.028277 ## iter 4 value -0.098572 ## iter 5 value -0.099166 ## iter 6 value -0.110909 ## iter 7 value -0.120755 ## iter 8 value -0.124837 ## iter 9 value -0.124959 ## iter 10 value -0.125052 ## iter 11 value -0.125129 ## iter 12 value -0.125237 ## iter 13 value -0.125495 ## iter 14 value -0.125867 ## iter 15 value -0.126036 ## iter 16 value -0.126273 ## iter 17 value -0.126333 ## iter 18 value -0.126349 ## iter 19 value -0.126373 ## iter 20 value -0.126443 ## iter 21 value -0.126595 ## iter 22 value -0.126766 ## iter 23 value -0.126833 ## iter 24 value -0.126851 ## iter 25 value -0.126853 ## iter 26 value -0.126858 ## iter 27 value -0.126871 ## iter 28 value -0.126875 ## iter 29 value -0.126878 ## iter 30 value -0.126879 ## iter 31 value -0.126884 ## iter 32 value -0.126932 ## iter 33 value -0.127033 ## iter 34 value -0.127249 ## iter 35 value -0.127426 ## iter 36 value -0.127571 ## iter 37 value -0.127579 ## iter 38 value -0.127595 ## iter 39 value -0.127606 ## iter 40 value -0.127677 ## iter 41 value -0.127680 ## iter 42 value -0.127690 ## iter 43 value -0.127700 ## iter 44 value -0.127717 ## iter 45 value -0.127735 ## iter 46 value -0.127777 ## iter 47 value -0.127782 ## iter 48 value -0.127783 ## iter 49 value -0.127783 ## iter 50 value -0.127786 ## iter 51 value -0.127792 ## iter 52 value -0.127807 ## iter 53 value -0.127833 ## iter 54 value -0.127845 ## iter 55 value -0.127851 ## iter 56 value -0.127856 ## iter 57 value -0.127859 ## iter 58 value -0.127861 ## iter 59 value -0.127861 ## iter 60 value -0.127862 ## iter 61 value -0.127863 ## iter 62 value -0.127864 ## iter 63 value -0.127865 ## iter 64 value -0.127866 ## iter 65 value -0.127867 ## iter 66 value -0.127869 ## iter 67 value -0.127870 ## iter 68 value -0.127870 ## iter 69 value -0.127871 ## iter 70 value -0.127872 ## iter 71 value -0.127872 ## iter 72 value -0.127873 ## iter 73 value -0.127874 ## iter 74 value -0.127874 ## iter 75 value -0.127874 ## iter 76 value -0.127874 ## iter 77 value -0.127875 ## iter 78 value -0.127876 ## iter 79 value -0.127878 ## iter 80 value -0.127878 ## iter 81 value -0.127879 ## iter 82 value -0.127879 ## iter 83 value -0.127879 ## iter 84 value -0.127879 ## iter 85 value -0.127879 ## iter 86 value -0.127879 ## iter 87 value -0.127879 ## iter 88 value -0.127879 ## iter 89 value -0.127879 ## iter 90 value -0.127879 ## iter 91 value -0.127879 ## iter 92 value -0.127880 ## iter 93 value -0.127880 ## iter 94 value -0.127880 ## iter 95 value -0.127880 ## iter 96 value -0.127880 ## iter 97 value -0.127880 ## iter 98 value -0.127880 ## iter 99 value -0.127880 ## iter 99 value -0.127880 ## iter 99 value -0.127880 ## final value -0.127880 ## converged ## initial value -0.128932 ## iter 2 value -0.128957 ## iter 3 value -0.128966 ## iter 4 value -0.129013 ## iter 5 value -0.129134 ## iter 6 value -0.129203 ## iter 7 value -0.129213 ## iter 8 value -0.129220 ## iter 9 value -0.129268 ## iter 10 value -0.129333 ## iter 11 value -0.129416 ## iter 12 value -0.129497 ## iter 13 value -0.129512 ## iter 14 value -0.129517 ## iter 15 value -0.129519 ## iter 16 value -0.129520 ## iter 17 value -0.129520 ## iter 18 value -0.129520 ## iter 19 value -0.129521 ## iter 20 value -0.129521 ## iter 21 value -0.129521 ## iter 22 value -0.129521 ## iter 23 value -0.129521 ## iter 24 value -0.129521 ## iter 25 value -0.129522 ## iter 26 value -0.129522 ## iter 27 value -0.129522 ## iter 28 value -0.129522 ## iter 29 value -0.129522 ## iter 30 value -0.129522 ## iter 31 value -0.129522 ## iter 32 value -0.129522 ## iter 33 value -0.129522 ## iter 34 value -0.129522 ## iter 34 value -0.129522 ## iter 34 value -0.129522 ## final value -0.129522 ## converged ## $fit ## ## Call: ## arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, Q), period = S), ## xreg = constant, transform.pars = trans, fixed = fixed, optim.control = list(trace = trc, ## REPORT = 1, reltol = tol)) ## ## Coefficients: ## ar1 ar2 ma1 ma2 ma3 constant ## -1.2476 -0.7577 0.3925 -0.2267 -0.6812 -0.0024 ## s.e. 0.2052 0.1961 0.1983 0.0740 0.1359 0.0064 ## ## sigma^2 estimated as 0.7698: log likelihood = -653.73, aic = 1321.47 ## ## $degrees_of_freedom ## [1] 501 ## ## $ttable ## Estimate SE t.value p.value ## ar1 -1.2476 0.2052 -6.0804 0.0000 ## ar2 -0.7577 0.1961 -3.8634 0.0001 ## ma1 0.3925 0.1983 1.9794 0.0483 ## ma2 -0.2267 0.0740 -3.0649 0.0023 ## ma3 -0.6812 0.1359 -5.0137 0.0000 ## constant -0.0024 0.0064 -0.3795 0.7045 ## ## $AIC ## [1] 2.606446 ## ## $AICc ## [1] 2.606777 ## ## $BIC ## [1] 2.664828 so2_model &lt;- arima(so2, order = c(2, 1, 3)) prediction &lt;- predict(so2_model,n.ahead = 4,interval = &quot;prediction&quot;, level = 0.95) lower_bound &lt;- prediction$pred - 1.96 * prediction$se upper_bound &lt;- prediction$pred + 1.96 * prediction$se prediction_interval &lt;- cbind(lower_bound,prediction$pred,upper_bound) prediction_interval ## Time Series: ## Start = c(1979, 41) ## End = c(1979, 44) ## Frequency = 52 ## lower_bound prediction$pred upper_bound ## 1979.769 0.04660457 1.766520 3.486436 ## 1979.788 0.14831777 1.886338 3.624358 ## 1979.808 0.01768271 1.799397 3.581111 ## 1979.827 0.02834286 1.817085 3.605828 5.7 5.7 auto.arima(AirPassengers) ## Series: AirPassengers ## ARIMA(2,1,1)(0,1,0)[12] ## ## Coefficients: ## ar1 ar2 ma1 ## 0.5960 0.2143 -0.9819 ## s.e. 0.0888 0.0880 0.0292 ## ## sigma^2 = 132.3: log likelihood = -504.92 ## AIC=1017.85 AICc=1018.17 BIC=1029.35 AirPassengers_model &lt;- arima(AirPassengers, order = c(2, 1, 1)) 5.8 5.8 phi = c(rep(0,11),8) ACF = ARMAacf(ar=phi, ma=-.5,50)[-1] PACF = ARMAacf(ar=phi, ma=-.5,50,pacf = TRUE) LAG=1:50/12 plot(LAG,ACF,type=&quot;h&quot;,ylim=c(-.4,.8),panel.first=Grid()) abline(h=0) 5.9 5.9 summary(chicken) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 61.49 72.42 85.03 85.67 96.04 116.00 auto.arima(chicken) ## Series: chicken ## ARIMA(2,1,1)(0,0,1)[12] with drift ## ## Coefficients: ## ar1 ar2 ma1 sma1 drift ## 1.2933 -0.5375 -0.4019 0.2756 0.2518 ## s.e. 0.2220 0.1542 0.2569 0.0692 0.1428 ## ## sigma^2 = 0.396: log likelihood = -169.51 ## AIC=351.01 AICc=351.5 BIC=370.14 # 拟合ARIMA模型 chicken_model &lt;- arima(chicken, order = c(2, 1, 1)) # 对未来12个月进行预测 chicken_forecast &lt;- predict(chicken_model, n.ahead = 12) # 打印预测结果 print(chicken_forecast$pred) ## Jan Feb Mar Apr May Jun Jul Aug ## 2016 111.1112 ## 2017 110.7738 110.8189 110.8526 110.8717 110.8785 110.8772 110.8721 ## Sep Oct Nov Dec ## 2016 110.8680 110.7415 110.7072 110.7290 ## 2017 # 绘制原始数据和预测结果的图形 plot(chicken, type = &quot;l&quot;, xlab = &quot;时间&quot;, ylab = &quot;销售量&quot;, main = &quot;Chicken Sales&quot;) lines(chicken_forecast$pred, col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;原始数据&quot;, &quot;预测结果&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = c(1, 1)) 5.10 5.10 summary(UnempRate) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.400 4.700 5.600 5.812 6.900 11.400 #auto.arima(UnempRate) # 拟合ARIMA模型 UnempRate_model &lt;- arima(UnempRate, order = c(2, 1, 2)) # 对未来12个月进行预测 UnempRate_forecast &lt;- predict(UnempRate_model, n.ahead = 12) # 打印预测结果 print(chicken_forecast$pred) ## Jan Feb Mar Apr May Jun Jul Aug ## 2016 111.1112 ## 2017 110.7738 110.8189 110.8526 110.8717 110.8785 110.8772 110.8721 ## Sep Oct Nov Dec ## 2016 110.8680 110.7415 110.7072 110.7290 ## 2017 # 绘制原始数据和预测结果的图形 plot(UnempRate, type = &quot;l&quot;, xlab = &quot;时间&quot;, ylab = &quot;销售量&quot;, main = &quot;UnempRate&quot;) lines(UnempRate_forecast$pred, col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;原始数据&quot;, &quot;预测结果&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = c(1, 1)) 5.11 5.11 summary(birth) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 238.0 284.0 310.0 310.9 336.0 399.0 auto.arima(birth) ## Series: birth ## ARIMA(0,1,2)(1,1,1)[12] ## ## Coefficients: ## ma1 ma2 sar1 sma1 ## -0.3984 -0.1632 0.1018 -0.8434 ## s.e. 0.0512 0.0486 0.0713 0.0476 ## ## sigma^2 = 46.1: log likelihood = -1204.93 ## AIC=2419.86 AICc=2420.03 BIC=2439.29 # 拟合ARIMA模型 birth_model &lt;- arima(birth, order = c(1, 1, 1)) # 对未来12个月进行预测 birth_forecast &lt;- predict(birth_model, n.ahead = 12) # 打印预测结果 print(birth_forecast$pred) ## Jan Feb Mar Apr May Jun Jul Aug ## 1979 278.5900 277.8638 278.1955 278.0440 278.1132 278.0816 278.0960 ## 1980 278.0914 ## Sep Oct Nov Dec ## 1979 278.0894 278.0924 278.0911 278.0917 ## 1980 # 绘制原始数据和预测结果的图形 plot(birth, type = &quot;l&quot;, xlab = &quot;时间&quot;, ylab = &quot;销售量&quot;, main = &quot;birth&quot;) lines(birth_forecast$pred, col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;原始数据&quot;, &quot;预测结果&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = c(1, 1)) 5.12 5.12 summary(log(jj)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -0.8210 0.2211 1.2553 1.1044 1.9635 2.7850 auto.arima(log(jj)) ## Series: log(jj) ## ARIMA(2,0,0)(1,1,0)[4] with drift ## ## Coefficients: ## ar1 ar2 sar1 drift ## 0.2686 0.2855 -0.2695 0.0382 ## s.e. 0.1137 0.1214 0.1212 0.0042 ## ## sigma^2 = 0.007793: log likelihood = 82.47 ## AIC=-154.95 AICc=-154.14 BIC=-143.04 # 拟合ARIMA模型 jj_model &lt;- arima(log(jj), order = c(1, 1, 0)) # 对未来12个月进行预测 jj_forecast &lt;- predict(jj_model, n.ahead = 4) # 打印预测结果 print(birth_forecast$pred) ## Jan Feb Mar Apr May Jun Jul Aug ## 1979 278.5900 277.8638 278.1955 278.0440 278.1132 278.0816 278.0960 ## 1980 278.0914 ## Sep Oct Nov Dec ## 1979 278.0894 278.0924 278.0911 278.0917 ## 1980 # 绘制原始数据和预测结果的图形 plot(log(jj), type = &quot;l&quot;, xlab = &quot;时间&quot;, ylab = &quot;销售量&quot;, main = &quot;jj&quot;) lines(jj_forecast$pred, col = &quot;red&quot;) legend(&quot;topleft&quot;, legend = c(&quot;原始数据&quot;, &quot;预测结果&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = c(1, 1)) "]]
